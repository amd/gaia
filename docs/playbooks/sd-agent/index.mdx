---
title: "Building a Multi-Modal Image Generation Agent"
description: "Learn to build agents that combine LLM reasoning, Stable Diffusion, and Vision models"
icon: "image"
---

<Info>
  **Source Code:** [`src/gaia/agents/sd/agent.py`](https://github.com/amd/gaia/blob/main/src/gaia/agents/sd/agent.py)
</Info>

<Badge text="development" color="orange" />

<video
  controls
  autoPlay
  loop
  muted
  playsInline
  className="w-full rounded-lg"
  src="https://assets.amd-gaia.ai/videos/gaia-sdxl-agent.webm"
/>

Build a multi-modal agent that generates images and creates stories. Type "robot exploring ancient ruins" → Get image + story in ~35 seconds. Three AI models working together, all running locally on AMD hardware.

---

## Learning Path

<CardGroup cols={3}>
  <Card title="Part 1: Build Your Agent" icon="rocket" href="/playbooks/sd-agent/part-1-building-agent">
    **25 minutes**

    Build and run your first multi-modal agent from scratch.
  </Card>

  <Card title="Part 2: Architecture" icon="diagram-project" href="/playbooks/sd-agent/part-2-architecture">
    **20 minutes**

    Understand how multi-modal agents work under the hood.
  </Card>

  <Card title="Part 3: Variations" icon="wand-magic-sparkles" href="/playbooks/sd-agent/part-3-variations">
    **20 minutes**

    Apply patterns to real-world use cases.
  </Card>
</CardGroup>

---

## Quick Test

<Note>
**First time?** See [Setup Guide](/setup) to install prerequisites (uv, Python, AMD drivers).
</Note>

Want to try it first before building?

Install models and start Lemonade Server:
```bash
gaia init --profile sd
```

Generate one image + story with the built-in agent:
```bash
gaia sd "generate an image of a robot exploring ancient ruins and tell me the story of what it discovers"
```

---

<Card title="Start Building →" icon="play" href="/playbooks/sd-agent/part-1-building-agent" iconType="solid">
  Jump into Part 1 and build your first multi-modal agent
</Card>
