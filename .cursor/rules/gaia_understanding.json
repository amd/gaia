{
  "project_understanding": {
    "gaia": {
      "description": "GAIA (Generative AI is Awesome) is an open-source framework for running generative AI applications on AMD hardware",
      "documentation_source": "../docs.json",
      "key_components": {
        "backend": {
          "description": "Supports both OGA/Lemonade and Ollama backends for LLM execution",
          "stack": {
            "lemonade": {
              "description": "Multi-vendor open-source SDK for LLM deployment",
              "interfaces": [
                "High-level Python SDK",
                "Server Interface (REST API)",
                "OGA APIs for C++ and Python"
              ],
              "features": [
                "Quick experimentation with hybrid execution mode",
                "Validation of inference speed and task performance",
                "High-level API integration for Python apps",
                "Server management and monitoring"
              ]
            },
            "oga": {
              "description": "Microsoft's multi-vendor generative AI framework",
              "role": "Provides LLM interface for execution backends like Ryzen AI"
            },
            "ollama": {
              "description": "Open-source LLM execution engine",
              "role": "Provides alternative backend for non-Ryzen AI systems",
              "features": [
                "Model management",
                "Server-based execution",
                "Generic CPU/GPU support"
              ]
            }
          }
        },
        "modes": {
          "hybrid": {
            "description": "Utilizes both NPU and iGPU on Ryzen AI systems",
            "features": [
              "Optimal model partitioning between NPU and iGPU",
              "Minimized time-to-first-token (TTFT)",
              "Maximized token generation speed (TPS)",
              "Automatic server management"
            ],
            "requirements": [
              "Ryzen AI 300-series processors (Strix Point/Krackan Point)",
              "Windows 11"
            ]
          },
          "npu": {
            "description": "NPU-only execution mode (Early Access)",
            "features": ["Compute-intensive operations offloaded exclusively to NPU"],
            "platforms": ["STX", "KRK"]
          },
          "generic": {
            "description": "Runs on non-Ryzen AI systems using standard CPU/GPU",
            "features": [
              "Ollama-based execution",
              "Wide hardware compatibility",
              "Automatic server management"
            ]
          }
        },
        "features": [
          "Local/private LLM execution",
          "RAG (Retrieval-Augmented Generation) pipeline",
          "Interactive chat capabilities",
          "Tool usage and reasoning",
          "Automatic server management",
          "Multiple backend support"
        ],
        "optional_components": {
          "raux": {
            "description": "AMD's beta UI for AI model interaction",
            "installation": "Optional component in GAIA installer",
            "integration": "Installed separately but can be managed through GAIA installer",
            "server_interaction": "Uses GAIA's server management capabilities"
          }
        }
      },
      "file_patterns": {
        "core": ["gaia/**/*.py"],
        "agents": ["gaia/agents/**/*.py"],
        "llm": ["gaia/llm/**/*.py"],
        "interface": ["gaia/interface/**/*"],
        "tests": ["tests/**/*.py"],
        "docs": ["docs/**/*.md"],
        "workflows": [".github/workflows/**/*.yml"]
      },
      "installer": {
        "modes": ["hybrid", "npu", "generic"],
        "optional_components": ["RAUX"],
        "dependencies": {
          "python": "Includes embedded Python distribution",
          "ollama": "Required for generic mode",
          "packages": "Automatically installs required Python packages"
        }
      }
    }
  }
} 