{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.2.1\n",
    "!pip install groq\n",
    "!pip install sentence-transformers==2.6.0\n",
    "!pip install llama-index==0.10.20\n",
    "!pip install python-dotenv==1.0.1\n",
    "!pip install llama-index-embeddings-huggingface==0.1.4\n",
    "!pip install llama-index-readers-web==0.1.9\n",
    "!pip install youtube_transcript_api==0.6.2\n",
    "!pip install llama-index-readers-youtube-transcript==0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "assert openai.api_key, 'Please set OPENAI_API_KEY!'\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "assert groq_api_key, 'Please set GROQ_API_KEY!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "def groq_chat(system_prompt, query, model=\"llama-3.1-8b-instant\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Document,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    DocumentSummaryIndex,\n",
    "    SummaryIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    get_response_synthesizer\n",
    ")\n",
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "def get_youtube_transcript_doc(yt_links:list)->Document:\n",
    "    return YoutubeTranscriptReader().load_data(ytlinks=yt_links)\n",
    "\n",
    "def build_vector_index(doc:Document, persist_dir=None)->VectorStoreIndex:\n",
    "    if persist_dir:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "        index = VectorStoreIndex.load_from_storage(storage_context)\n",
    "    else:\n",
    "        index = VectorStoreIndex.from_documents(doc, show_progress=True)\n",
    "    return index\n",
    "\n",
    "def build_summary_index(doc:Document, persist_dir=None)->SummaryIndex:\n",
    "    if persist_dir:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "        index = DocumentSummaryIndex.load_from_storage(storage_context)\n",
    "    else:\n",
    "        # from https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "        # LLM (gpt-3.5-turbo)\n",
    "        chatgpt = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "        splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "        # default mode of building the index\n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"tree_summarize\", use_async=True\n",
    "        )\n",
    "        index = DocumentSummaryIndex.from_documents(\n",
    "            doc,\n",
    "            llm=chatgpt,\n",
    "            transformations=[splitter],\n",
    "            response_synthesizer=response_synthesizer,\n",
    "            show_progress=True,\n",
    "        )\n",
    "    return index\n",
    "\n",
    "def get_query_engine(index, similarity_top=3):\n",
    "    return index.as_query_engine(similarity_top_k=similarity_top)\n",
    "\n",
    "def get_youtube_tool():\n",
    "    return FunctionTool.from_defaults(fn=get_youtube_transcript_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an example Vector Index from a YouTube Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intro to LLMs, Andrej Karpathy\n",
    "yt_links = [\"https://www.youtube.com/watch?v=zjkBMFhNj_g\"]\n",
    "\n",
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "# yt_links = [\"https://www.youtube.com/watch?v=MCi8jgALPYA\"]\n",
    "\n",
    "yt_doc = get_youtube_transcript_doc(yt_links)\n",
    "yt_vector_index = build_vector_index(yt_doc)\n",
    "\n",
    "yt_engine = get_query_engine(yt_vector_index)\n",
    "# yt_tool = get_youtube_tool(transcript_doc)\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=yt_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"youtube\",\n",
    "            description=(\n",
    "                \"YouTube transcript of Andrej Karpathy's Introduction to LLMs. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_doc = get_youtube_transcript_doc(yt_links)\n",
    "doc_id = \"youtube_doc\"\n",
    "yt_doc[0].doc_id = doc_id\n",
    "yt_summary_index = build_summary_index(yt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yt_summary_index.get_document_summary(doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's a neural network?\"\n",
    "response = yt_engine.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "# llm = OpenAI(model=\"gpt-4\")\n",
    "llm = LocalLLM()\n",
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"(use the youtube tool)\"\n",
    "queries = [\n",
    "    # \"Summarize to just the main takeaways.\",\n",
    "    # \"What is a LLM according to Andrej Karpathy?\",\n",
    "    # \"How does it work?\",\n",
    "    \"How do you train ChatGPT?\",\n",
    "    \"What's system 1 vs. system 2 thinking?\",\n",
    "    \"What were the two main stages of AlphaGo?\",\n",
    "    \"What will an LLM OS be able to do in a few years?\",\n",
    "    \"How do you jailbreak an LLM?\",\n",
    "    \"How do you do prompt injection?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    response = agent.chat(f\"{query}\\n{hint}\")\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input()\n",
    "    if not user_input:\n",
    "        break\n",
    "    print(f\"User: {user_input}\")\n",
    "    response = agent.chat(user_input)\n",
    "    print(f\"Agent: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "youtube_api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "assert youtube_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and process youtube transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_video_id(url):\n",
    "    patterns = [\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/watch\\?v=([^&]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtu\\.be\\/([^?]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/embed\\/([^?]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/v\\/([^?]+)',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fetch_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript(transcript, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(transcript, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def print_transcript(transcript):\n",
    "    for entry in transcript:\n",
    "        start_time = entry['start']\n",
    "        duration = entry['duration']\n",
    "        text = entry['text']\n",
    "        end_time = start_time + duration\n",
    "        \n",
    "        # Format timestamp as HH:MM:SS\n",
    "        start_formatted = format_timestamp(start_time)\n",
    "        end_formatted = format_timestamp(end_time)\n",
    "        \n",
    "        print(f\"[{start_formatted} - {end_formatted}] {text}\")\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "def save_formatted_transcript(transcript, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for entry in transcript:\n",
    "            start_time = entry['start']\n",
    "            duration = entry['duration']\n",
    "            text = entry['text']\n",
    "            end_time = start_time + duration\n",
    "            \n",
    "            start_formatted = format_timestamp(start_time)\n",
    "            end_formatted = format_timestamp(end_time)\n",
    "            \n",
    "            f.write(f\"[{start_formatted} - {end_formatted}] {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playback YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "from pytube import YouTube\n",
    "import time\n",
    "\n",
    "def download_youtube_video(video_id, temp_dir=None):\n",
    "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    \n",
    "    try:\n",
    "        yt = YouTube(video_url)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "\n",
    "        # Create a temporary directory\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # Download the video\n",
    "        print(\"Downloading video...\")\n",
    "        video_path = stream.download(output_path=temp_dir)\n",
    "        print(f\"Video downloaded to: {video_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading and trimming: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return temp_dir, video_path\n",
    "\n",
    "\n",
    "def trim_youtube_video(video_path, start_time, end_time, temp_dir=None):\n",
    "    try:\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # Trim the video using ffmpeg\n",
    "        output_path = os.path.join(temp_dir, 'video.mp4')\n",
    "        duration = end_time - start_time\n",
    "        ffmpeg_command = f'ffmpeg -i \"{video_path}\" -ss {start_time} -t {duration} -c copy \"{output_path}\"'\n",
    "\n",
    "        print(\"Trimming video...\")\n",
    "        print(f\"FFmpeg command: {ffmpeg_command}\")\n",
    "        result = subprocess.run(ffmpeg_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"FFmpeg error: {result.stderr}\")\n",
    "            raise Exception(\"FFmpeg failed to trim the video\")\n",
    "\n",
    "        print(f\"Trimmed video saved to: {output_path}\")\n",
    "\n",
    "        if not os.path.exists(output_path):\n",
    "            raise FileNotFoundError(f\"Trimmed video file not found: {output_path}\")\n",
    "\n",
    "        return temp_dir, output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading and trimming: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def play_youtube_video(video_path, duration):\n",
    "    try:\n",
    "        # Convert to absolute path\n",
    "        abs_video_path = os.path.abspath(video_path)\n",
    "        print(f\"Absolute video path: {abs_video_path}\")\n",
    "\n",
    "        if not os.path.exists(abs_video_path):\n",
    "            raise FileNotFoundError(f\"Video file not found: {abs_video_path}\")\n",
    "\n",
    "        print(f\"Attempting to play video: {abs_video_path}\")\n",
    "\n",
    "        # Play the trimmed video with the default player\n",
    "        if os.name == 'nt':  # For Windows\n",
    "            print(\"Using subprocess method...\")\n",
    "            subprocess.Popen(['start', '', abs_video_path], shell=True)\n",
    "        else:\n",
    "            raise NotImplementedError(\"This script currently supports Windows only\")\n",
    "\n",
    "        print(\"Default player command executed.\")\n",
    "\n",
    "        # Wait for the duration of the video\n",
    "        print(f\"Waiting for {duration} seconds...\")\n",
    "        time.sleep(duration + 2)  # Add a small buffer\n",
    "\n",
    "        print(\"Playback duration completed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while playing: {e}\")\n",
    "\n",
    "    print(\"Function play_youtube_video completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "def trim_and_stitch_youtube_video(video_path, time_segments, output_path, temp_dir=None):\n",
    "    try:\n",
    "        assert os.path.isfile(file_path), f\"ERROR: {video_path} doesn't exist\"\n",
    "\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # List to store paths of trimmed segments\n",
    "        trimmed_segments = []\n",
    "\n",
    "        # Trim each segment\n",
    "        for i, (start_time, end_time) in enumerate(time_segments):\n",
    "            segment_path = os.path.join(temp_dir, f'segment_{i}.mp4')\n",
    "            duration = end_time - start_time\n",
    "            ffmpeg_command = f'ffmpeg -i \"{video_path}\" -ss {start_time} -t {duration} -c copy \"{segment_path}\"'\n",
    "\n",
    "            print(f\"Trimming segment {i+1}/{len(time_segments)}...\")\n",
    "            print(f\"FFmpeg command: {ffmpeg_command}\")\n",
    "            result = subprocess.run(ffmpeg_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                print(f\"FFmpeg error: {result.stderr}\")\n",
    "                raise Exception(f\"FFmpeg failed to trim segment {i+1}\")\n",
    "\n",
    "            trimmed_segments.append(segment_path)\n",
    "\n",
    "        # Create a file list for concatenation\n",
    "        list_file_path = os.path.join(temp_dir, 'file_list.txt')\n",
    "        with open(list_file_path, 'w') as list_file:\n",
    "            for segment in trimmed_segments:\n",
    "                list_file.write(f\"file '{segment}'\\n\")\n",
    "\n",
    "        # Concatenate all segments\n",
    "        concat_command = f'ffmpeg -f concat -safe 0 -i \"{list_file_path}\" -c copy \"{output_path}\" -y'\n",
    "        print(\"Concatenating segments...\")\n",
    "        print(f\"FFmpeg command: {concat_command}\")\n",
    "        result = subprocess.run(concat_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"FFmpeg error: {result.stderr}\")\n",
    "            raise Exception(\"FFmpeg failed to concatenate the segments\")\n",
    "\n",
    "        print(f\"Final video saved to: {output_path}\")\n",
    "\n",
    "        if not os.path.exists(output_path):\n",
    "            raise FileNotFoundError(f\"Final video file not found: {output_path}\")\n",
    "\n",
    "        return temp_dir, output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trimming and stitching: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage:\n",
    "video_path = \"path/to/your/video.mp4\"\n",
    "time_segments = [(10, 20), (30, 40), (50, 60)]  # List of (start_time, end_time) tuples\n",
    "output_path = \"path/to/output/final_video.mp4\"\n",
    "\n",
    "temp_dir, final_video_path = trim_and_stitch_youtube_video(video_path, time_segments, output_path)\n",
    "\n",
    "if temp_dir and final_video_path:\n",
    "    print(\"Video processing completed successfully!\")\n",
    "    # Don't forget to clean up the temp_dir when you're done\n",
    "else:\n",
    "    print(\"Video processing failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "youtube_url = 'https://www.youtube.com/watch?v=MCi8jgALPYA'\n",
    "\n",
    "start_time = 45  # Start time in seconds\n",
    "end_time = 67    # End time in seconds\n",
    "\n",
    "temp_dir, video_path = download_youtube_video(youtube_url, './')\n",
    "temp_dir, video_path = trim_youtube_video(video_path, start_time, end_time, './')\n",
    "# video_path = \"C:\\\\Users\\\\kovtchar\\\\Work\\\\gaia\\\\notebooks\\\\video.mp4\"\n",
    "play_youtube_video(video_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "youtube_url = 'https://www.youtube.com/watch?v=MCi8jgALPYA'\n",
    "\n",
    "start_time = 45  # Start time in seconds\n",
    "end_time = 67    # End time in seconds\n",
    "\n",
    "video_id = extract_video_id(youtube_url)\n",
    "\n",
    "if video_id:\n",
    "    print(f\"Extracted Video ID: {video_id}\")\n",
    "    transcript = fetch_transcript(video_id)\n",
    "\n",
    "    if transcript:\n",
    "        # Save the structured transcript (with timestamps)\n",
    "        save_transcript(transcript, 'transcript_structured.json')\n",
    "        save_formatted_transcript(transcript, 'transcript_formatted.txt')\n",
    "        print_transcript(transcript)\n",
    "\n",
    "        temp_dir, video_path = download_youtube_segment(video_id, start_time, end_time)\n",
    "        if temp_dir and video_path:\n",
    "            try:\n",
    "                play_video_segment(video_path, end_time - start_time)\n",
    "            finally:\n",
    "                # Clean up: remove the temporary directory and its contents\n",
    "                print(f\"Cleaning up temporary directory: {temp_dir}\")\n",
    "                for file in os.listdir(temp_dir):\n",
    "                    os.remove(os.path.join(temp_dir, file))\n",
    "                os.rmdir(temp_dir)\n",
    "        else:\n",
    "            print(\"Failed to download and trim the video segment.\")\n",
    "                play_youtube_segment(video_id, start_time, end_time)\n",
    "    else:\n",
    "        print(\"Could not extract a valid YouTube video ID from the provided URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_youtube_segment(video_id, start_time, end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
