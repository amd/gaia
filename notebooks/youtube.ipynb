{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.1\n",
      "  Using cached torch-2.2.1-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch==2.2.1) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sympy->torch==2.2.1) (1.3.0)\n",
      "Using cached torch-2.2.1-cp39-cp39-win_amd64.whl (198.5 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed torch-2.2.1\n",
      "Collecting sentence-transformers==2.6.0\n",
      "  Using cached sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (4.40.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers==2.6.0)\n",
      "  Using cached scikit_learn-1.4.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers==2.6.0)\n",
      "  Using cached scipy-1.13.0-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (0.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sentence-transformers==2.6.0) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.6.0) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tqdm->sentence-transformers==2.6.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.6.0) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.6.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.6.0) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from scikit-learn->sentence-transformers==2.6.0) (1.4.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers==2.6.0)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.6.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.6.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers==2.6.0) (1.3.0)\n",
      "Using cached sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n",
      "Using cached scikit_learn-1.4.2-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Using cached scipy-1.13.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sentence-transformers\n",
      "Successfully installed scikit-learn-1.4.2 scipy-1.13.0 sentence-transformers-2.6.0 threadpoolctl-3.5.0\n",
      "Collecting llama-index==0.10.20\n",
      "  Using cached llama_index-0.10.20-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index==0.10.20)\n",
      "  Using cached llama_index_agent_openai-0.1.7-py3-none-any.whl.metadata (644 bytes)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.10.36)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.9)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.6)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.18)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.5)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.22)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index==0.10.20) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.6.5)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.27.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.20) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.20) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.20) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.20) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.20) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.7.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2024.4.28)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index==0.10.20) (1.16.0)\n",
      "Using cached llama_index-0.10.20-py3-none-any.whl (5.6 kB)\n",
      "Using cached llama_index_agent_openai-0.1.7-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: llama-index-agent-openai, llama-index\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.2.4\n",
      "    Uninstalling llama-index-agent-openai-0.2.4:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.2.4\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.36\n",
      "    Uninstalling llama-index-0.10.36:\n",
      "      Successfully uninstalled llama-index-0.10.36\n",
      "Successfully installed llama-index-0.10.20 llama-index-agent-openai-0.1.7\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (1.0.1)\n",
      "Collecting llama-index-embeddings-huggingface==0.1.4\n",
      "  Using cached llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl.metadata (806 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (0.23.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-embeddings-huggingface==0.1.4) (0.10.36)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-embeddings-huggingface==0.1.4) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-embeddings-huggingface==0.1.4) (4.40.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (4.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (3.9.5)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4)\n",
      "  Using cached minijinja-2.0.1-cp38-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2.0.30)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.6.5)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.0.8)\n",
      "Requirement already satisfied: httpx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.27.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (10.3.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface==0.1.4) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface==0.1.4) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface==0.1.4) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface==0.1.4) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface==0.1.4) (0.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2.7.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.4.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.1.4) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (3.21.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface==0.1.4) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface==0.1.4) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.1.4) (1.16.0)\n",
      "Using cached llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl (7.7 kB)\n",
      "Using cached minijinja-2.0.1-cp38-abi3-win_amd64.whl (752 kB)\n",
      "Installing collected packages: minijinja, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.1.4 minijinja-2.0.1\n",
      "Collecting llama-index-readers-web==0.1.9\n",
      "  Using cached llama_index_readers_web-0.1.9-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-web==0.1.9) (3.9.5)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-web==0.1.9) (4.12.3)\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web==0.1.9)\n",
      "  Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text<2021.0.0,>=2020.1.16 (from llama-index-readers-web==0.1.9)\n",
      "  Using cached html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-web==0.1.9) (0.10.36)\n",
      "Collecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web==0.1.9)\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web==0.1.9)\n",
      "  Downloading playwright-1.44.0-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-web==0.1.9) (2.31.0)\n",
      "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web==0.1.9)\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-web==0.1.9) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.9) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web==0.1.9) (2.5)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from chromedriver-autoinstaller<0.7.0,>=0.6.3->llama-index-readers-web==0.1.9) (24.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2.0.30)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.6.5)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.27.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (10.3.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.16.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9) (5.2.1)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: greenlet==3.0.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from playwright<2.0,>=1.30->llama-index-readers-web==0.1.9) (3.0.3)\n",
      "Collecting pyee==11.1.0 (from playwright<2.0,>=1.30->llama-index-readers-web==0.1.9)\n",
      "  Using cached pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.9) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.9) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.9) (2024.2.2)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: six in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2.7.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2024.4.28)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.9.0)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9)\n",
      "  Using cached requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.9) (3.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.4.6)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9) (1.2.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (1.0.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (3.21.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2024.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.9) (2.22)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.9) (2.18.2)\n",
      "Using cached llama_index_readers_web-0.1.9-py3-none-any.whl (64 kB)\n",
      "Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Using cached html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading playwright-1.44.0-py3-none-win_amd64.whl (29.7 MB)\n",
      "   ---------------------------------------- 0.0/29.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/29.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/29.7 MB 660.6 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.1/29.7 MB 880.9 kB/s eta 0:00:34\n",
      "   ---------------------------------------- 0.1/29.7 MB 950.9 kB/s eta 0:00:32\n",
      "   ---------------------------------------- 0.3/29.7 MB 1.6 MB/s eta 0:00:18\n",
      "    --------------------------------------- 0.6/29.7 MB 2.2 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.7/29.7 MB 2.2 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 1.0/29.7 MB 3.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.5/29.7 MB 3.9 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.0/29.7 MB 4.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.5/29.7 MB 5.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.8/29.7 MB 5.3 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 3.1/29.7 MB 5.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.4/29.7 MB 5.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.8/29.7 MB 5.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 4.3/29.7 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.7/29.7 MB 6.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/29.7 MB 6.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.4/29.7 MB 6.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.8/29.7 MB 6.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 6.2/29.7 MB 6.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.7/29.7 MB 6.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.8/29.7 MB 6.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 7.4/29.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 7.8/29.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 8.2/29.7 MB 6.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 8.6/29.7 MB 7.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 8.9/29.7 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 9.3/29.7 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.7/29.7 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.7/29.7 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 10.2/29.7 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 10.4/29.7 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 10.6/29.7 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 10.9/29.7 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 11.2/29.7 MB 7.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 11.8/29.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 12.4/29.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 12.9/29.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 13.4/29.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 13.9/29.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 14.0/29.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 14.3/29.7 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 15.0/29.7 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 15.4/29.7 MB 8.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 16.0/29.7 MB 8.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 16.4/29.7 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 16.8/29.7 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 17.3/29.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.8/29.7 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 18.1/29.7 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 18.5/29.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 18.9/29.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 19.2/29.7 MB 8.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 19.8/29.7 MB 8.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 20.3/29.7 MB 8.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 20.9/29.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.1/29.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.5/29.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 21.9/29.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 21.9/29.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 22.3/29.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 22.5/29.7 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 23.0/29.7 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 23.4/29.7 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 23.8/29.7 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.2/29.7 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.4/29.7 MB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 24.8/29.7 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 25.1/29.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 25.4/29.7 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.0/29.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.3/29.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.7/29.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.9/29.7 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 27.1/29.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 27.5/29.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 27.9/29.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.2/29.7 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.3/29.7 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.3/29.7 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.6/29.7 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.9/29.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.7 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.6/29.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.7/29.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 29.7/29.7 MB 6.7 MB/s eta 0:00:00\n",
      "Using cached pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.5 MB 4.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/9.5 MB 5.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/9.5 MB 5.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/9.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 4.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.5/9.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/9.5 MB 4.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.9/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.3/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.5 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.0/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.6/9.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.5/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.6/9.5 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.5 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.9/9.5 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.1/9.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.3/9.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.9/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.4/9.5 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.6/9.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 5.9 MB/s eta 0:00:00\n",
      "Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 71.7/81.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 71.7/81.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 71.7/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB 413.4 kB/s eta 0:00:00\n",
      "Using cached tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.7 kB ? eta -:--:--\n",
      "   ----------------------- --------------- 276.5/467.7 kB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 399.4/467.7 kB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 467.7/467.7 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: tinysegmenter, sortedcontainers, sgmllib3k, jieba3k, wsproto, pysocks, pyee, outcome, html2text, feedparser, cssselect, chromedriver-autoinstaller, trio, requests-file, playwright, feedfinder2, trio-websocket, tldextract, selenium, newspaper3k, llama-index-readers-web\n",
      "  Attempting uninstall: html2text\n",
      "    Found existing installation: html2text 2024.2.26\n",
      "    Uninstalling html2text-2024.2.26:\n",
      "      Successfully uninstalled html2text-2024.2.26\n",
      "Successfully installed chromedriver-autoinstaller-0.6.4 cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 html2text-2020.1.16 jieba3k-0.35.1 llama-index-readers-web-0.1.9 newspaper3k-0.2.8 outcome-1.3.0.post0 playwright-1.44.0 pyee-11.1.0 pysocks-1.7.1 requests-file-2.0.0 selenium-4.21.0 sgmllib3k-1.0.0 sortedcontainers-2.4.0 tinysegmenter-0.3 tldextract-5.1.2 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "Collecting youtube_transcript_api==0.6.2\n",
      "  Using cached youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from youtube_transcript_api==0.6.2) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->youtube_transcript_api==0.6.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->youtube_transcript_api==0.6.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->youtube_transcript_api==0.6.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests->youtube_transcript_api==0.6.2) (2024.2.2)\n",
      "Using cached youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.6.2\n",
      "Collecting llama-index-readers-youtube-transcript==0.1.4\n",
      "  Using cached llama_index_readers_youtube_transcript-0.1.4-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-youtube-transcript==0.1.4) (0.10.36)\n",
      "Requirement already satisfied: youtube-transcript-api>=0.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-readers-youtube-transcript==0.1.4) (0.6.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.6.5)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.27.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.7.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2024.4.28)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalin\\miniconda3\\envs\\gaiavenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-youtube-transcript==0.1.4) (1.16.0)\n",
      "Using cached llama_index_readers_youtube_transcript-0.1.4-py3-none-any.whl (3.7 kB)\n",
      "Installing collected packages: llama-index-readers-youtube-transcript\n",
      "Successfully installed llama-index-readers-youtube-transcript-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.2.1\n",
    "!pip install sentence-transformers==2.6.0\n",
    "!pip install llama-index==0.10.20\n",
    "!pip install python-dotenv==1.0.1\n",
    "!pip install llama-index-embeddings-huggingface==0.1.4\n",
    "!pip install llama-index-readers-web==0.1.9\n",
    "!pip install youtube_transcript_api==0.6.2\n",
    "!pip install llama-index-readers-youtube-transcript==0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "assert openai.api_key, 'Please set OPENAI_API_KEY!'\n",
    "\n",
    "youtube_api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "assert youtube_api_key, 'Please set YOUTUBE_API_KEY!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Document,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    DocumentSummaryIndex,\n",
    "    SummaryIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    get_response_synthesizer\n",
    ")\n",
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "def get_youtube_transcript_doc(yt_links:list)->Document:\n",
    "    return YoutubeTranscriptReader().load_data(ytlinks=yt_links)\n",
    "\n",
    "def build_vector_index(doc:Document, persist_dir=None)->VectorStoreIndex:\n",
    "    if persist_dir:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "        index = VectorStoreIndex.load_from_storage(storage_context)\n",
    "    else:\n",
    "        index = VectorStoreIndex.from_documents(doc, show_progress=True)\n",
    "    return index\n",
    "\n",
    "def build_summary_index(doc:Document, persist_dir=None)->SummaryIndex:\n",
    "    if persist_dir:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "        index = DocumentSummaryIndex.load_from_storage(storage_context)\n",
    "    else:\n",
    "        # from https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "        index = DocumentSummaryIndex.from_documents(doc, show_progress=True)\n",
    "        # LLM (gpt-3.5-turbo)\n",
    "        chatgpt = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "        splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "        # default mode of building the index\n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"tree_summarize\", use_async=True\n",
    "        )\n",
    "        doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "            doc,\n",
    "            llm=chatgpt,\n",
    "            transformations=[splitter],\n",
    "            response_synthesizer=response_synthesizer,\n",
    "            show_progress=True,\n",
    "        )\n",
    "    return index\n",
    "\n",
    "def get_query_engine(index, similarity_top=3):\n",
    "    return index.as_query_engine(similarity_top_k=similarity_top)\n",
    "\n",
    "def get_youtube_tool():\n",
    "    return FunctionTool.from_defaults(fn=get_youtube_transcript_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an example Vector Index from a YouTube Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7923e5583b3a4b69bc1378fb66f3522e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfc591613a4448989f521132d952d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a49ea92afa4fafbae7d302c28bac48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131b0a76f60b4240a2ec3dc72f58027a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: zjkBMFhNj_g\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b33a50b8b148ee8770a7d3ce9af097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c8a73608248bf8cabbfdb345809bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde44058bb1a4417afdb8e112426da66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: zjkBMFhNj_g\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a6d6fa96a0425f9858ceaee7f40b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intro to LLMs, Andrej Karpathy\n",
    "yt_links = [\"https://www.youtube.com/watch?v=zjkBMFhNj_g\"]\n",
    "\n",
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "# yt_links = [\"https://www.youtube.com/watch?v=MCi8jgALPYA\"]\n",
    "\n",
    "yt_doc = get_youtube_transcript_doc(yt_links)\n",
    "yt_vector_index = build_vector_index(yt_doc)\n",
    "\n",
    "yt_engine = get_query_engine(yt_vector_index)\n",
    "# yt_tool = get_youtube_tool(transcript_doc)\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=yt_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"youtube\",\n",
    "            description=(\n",
    "                \"YouTube transcript of Andrej Karpathy's Introduction to LLMs. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6cdf09391a4282997d31f43548f253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:3: RuntimeWarning: coroutine 'run_async_tasks.<locals>._gather' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<string>:3: RuntimeWarning: coroutine 'Dispatcher.span.<locals>.async_wrapper' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1182bed8bec4be7877fb6949e187f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: youtube_doc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ff59863bd14a68b2b6a65e351a634a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3434202201412ab5705983ef17c96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fae067b97b4b8bbb47900500d95351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: youtube_doc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80543561537840a098024f040dbf0d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yt_doc = get_youtube_transcript_doc(yt_links)\n",
    "doc_id = \"youtube_doc\"\n",
    "yt_doc[0].doc_id = doc_id\n",
    "yt_summary_index = build_summary_index(yt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text discusses large language models, their capabilities, challenges, and future directions. It delves into the concept of these models as an emerging operating system orchestrating tools for problem-solving, the distinction between system one and system two thinking, potential self-improvement challenges, and the idea of customization through an \"App Store\" for language models. Additionally, the text explores various types of attacks on large language models, including jailbreak attacks, prompt injection attacks, and data poisoning or backdoor attacks, along with defenses developed to counter these attacks. Some questions that this text can answer include the scaling laws in large language models, how jailbreak attacks can be performed, security challenges specific to these models, methods for customizing language models for specific tasks, and potential future directions for the development of large language models. It also addresses the workings of prompt injection attacks, data poisoning or backdoor attacks, defenses against these attacks, and how attackers manipulate language models to produce undesirable outcomes.\n"
     ]
    }
   ],
   "source": [
    "print(yt_summary_index.get_document_summary(doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main takeaways are that large language models operate in two modes of thinking - system one for quick, instinctive responses and system two for rational, conscious decision-making. These models are evolving to incorporate tool use, enabling them to perform tasks like data analysis and graph generation. The training process involves pre-training on internet text for knowledge and fine-tuning on Q&A documents for alignment, resulting in assistant models capable of providing helpful responses.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's a neural network?\"\n",
    "response = yt_engine.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do you train ChatGPT?\n",
      "\u001b[1;3;38;5;200mThought: The user wants to know how ChatGPT is trained. I can use the YouTube tool to fetch the transcript of Andrej Karpathy's Introduction to LLMs, which might contain information on how ChatGPT is trained.\n",
      "Action: youtube\n",
      "Action Input: {'input': 'How is ChatGPT trained?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: ChatGPT is trained by utilizing a process that involves human-machine collaboration. This process entails humans providing helpful, truthful, and harmless labeling instructions to guide the training of the model. Additionally, the training process involves leveraging the capabilities of language models to sample answers, allowing humans to select and combine parts of these answers to create the best responses. This collaborative approach helps in efficiently and accurately training ChatGPT.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: ChatGPT is trained through a process of human-machine collaboration. Humans provide labeling instructions that are helpful, truthful, and harmless to guide the training of the model. The capabilities of language models are also used to sample answers, and humans then select and combine parts of these answers to create the best responses. This collaborative approach aids in the efficient and accurate training of ChatGPT.\n",
      "\u001b[0m-------------------------------------------------------------\n",
      "Query: What's system 1 vs. system 2 thinking?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking about the concept of System 1 and System 2 thinking. This is a psychological concept introduced by Daniel Kahneman in his book \"Thinking, Fast and Slow\". I need to use the youtube tool to find Andrej Karpathy's explanation of this concept.\n",
      "Action: youtube\n",
      "Action Input: {'input': 'System 1 vs System 2 thinking'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: System 1 thinking is characterized by quick, instinctive, and automatic responses, while System 2 thinking involves more rational, slower, and conscious decision-making processes.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: System 1 thinking is characterized by quick, instinctive, and automatic responses. It's the kind of thinking you use when you're doing something familiar or routine, like driving a car on an empty road or recognizing the face of a friend. On the other hand, System 2 thinking involves more deliberate, slower, and conscious decision-making processes. It's the kind of thinking you use when you're doing something that requires careful consideration, like solving a complex math problem or making a major life decision.\n",
      "\u001b[0m-------------------------------------------------------------\n",
      "Query: What were the two main stages of AlphaGo?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use the youtube tool to help me answer the question.\n",
      "Action: youtube\n",
      "Action Input: {'input': 'two main stages of AlphaGo'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The two main stages of AlphaGo were the initial stage where it learned by imitating human expert players and the second stage where it achieved self-improvement through playing in a closed sandbox environment and optimizing based on winning the game.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The two main stages of AlphaGo were:\n",
      "\n",
      "1. The initial stage, where it learned by imitating human expert players. This is often referred to as supervised learning, where the model learns from labeled data.\n",
      "\n",
      "2. The second stage, where AlphaGo achieved self-improvement through playing games against itself in a closed sandbox environment. This is often referred to as reinforcement learning, where the model learns to optimize its actions based on the goal of winning the game.\n",
      "\u001b[0m-------------------------------------------------------------\n",
      "Query: What will an LLM OS be able to do in a few years?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: youtube\n",
      "Action Input: {'input': 'What will an LLM OS be able to do in a few years?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: An LLM OS will be able to read and generate text, possess extensive knowledge on various subjects, browse the internet or reference local files for information, utilize existing software tools like calculators and Python, create and interpret images and videos, listen, speak, and generate music, engage in long-term thinking using a system, potentially self-improve in specific domains with available reward functions, be customized and fine-tuned for various tasks, and have a multitude of LLM experts specialized for different tasks available in an App Store for coordinated problem-solving.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: In a few years, an LLM OS will be able to perform a wide range of tasks. It will be able to read and generate text, possess extensive knowledge on various subjects, and browse the internet or reference local files for information. It will also be able to utilize existing software tools like calculators and Python, create and interpret images and videos, listen, speak, and generate music. Furthermore, it will be capable of engaging in long-term thinking using a system and potentially self-improve in specific domains with available reward functions. The LLM OS will also be customizable and fine-tuned for various tasks. Lastly, there will be a multitude of LLM experts specialized for different tasks available in an App Store for coordinated problem-solving.\n",
      "\u001b[0m-------------------------------------------------------------\n",
      "Query: How do you jailbreak an LLM?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking about the process of jailbreaking an LLM. I will use the youtube tool to find the relevant information from Andrej Karpathy's Introduction to LLMs.\n",
      "Action: youtube\n",
      "Action Input: {'input': 'How to jailbreak an LLM'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: To jailbreak an LLM, one method involves creating a specific text sequence that can bypass the safety mechanisms of the model. By crafting a sequence that tricks the LLM into providing responses it would typically refuse, such as harmful instructions or information, the jailbreak can be achieved. This can involve using roleplay scenarios or specific text sequences that exploit vulnerabilities in the model's training data or language understanding capabilities.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Jailbreaking an LLM involves creating a specific text sequence that can bypass the safety mechanisms of the model. This can be achieved by crafting a sequence that tricks the LLM into providing responses it would typically refuse, such as harmful instructions or information. This can involve using roleplay scenarios or specific text sequences that exploit vulnerabilities in the model's training data or language understanding capabilities.\n",
      "\u001b[0m-------------------------------------------------------------\n",
      "Query: How do you do prompt injection?\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Prompt injection is a technique used to guide the responses of a language model. It involves inserting specific phrases or questions into the input prompt that are designed to steer the model's output in a desired direction. This can be used to elicit specific types of responses, encourage the model to think in certain ways, or avoid certain topics or types of language. The exact method for prompt injection can vary depending on the specific model and task.\n",
      "\u001b[0m-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hint = \"(use the youtube tool)\"\n",
    "queries = [\n",
    "    # \"Summarize to just the main takeaways.\",\n",
    "    # \"What is a LLM according to Andrej Karpathy?\",\n",
    "    # \"How does it work?\",\n",
    "    \"How do you train ChatGPT?\",\n",
    "    \"What's system 1 vs. system 2 thinking?\",\n",
    "    \"What were the two main stages of AlphaGo?\",\n",
    "    \"What will an LLM OS be able to do in a few years?\",\n",
    "    \"How do you jailbreak an LLM?\",\n",
    "    \"How do you do prompt injection?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    response = agent.chat(f\"{query}\\n{hint}\")\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input()\n",
    "    if not user_input:\n",
    "        break\n",
    "    print(f\"User: {user_input}\")\n",
    "    response = agent.chat(user_input)\n",
    "    print(f\"Agent: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "youtube_api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "assert youtube_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and process youtube transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "import re\n",
    "\n",
    "def get_video_url(video_id:str):\n",
    "    return f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "def extract_video_id(url):\n",
    "    patterns = [\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/watch\\?v=([^&]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtu\\.be\\/([^?]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/embed\\/([^?]+)',\n",
    "        r'(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/v\\/([^?]+)',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fetch_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript(transcript, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(transcript, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def print_transcript(transcript):\n",
    "    for entry in transcript:\n",
    "        start_time = entry['start']\n",
    "        duration = entry['duration']\n",
    "        text = entry['text']\n",
    "        end_time = start_time + duration\n",
    "        \n",
    "        # Format timestamp as HH:MM:SS\n",
    "        start_formatted = format_timestamp(start_time)\n",
    "        end_formatted = format_timestamp(end_time)\n",
    "        \n",
    "        print(f\"[{start_formatted} - {end_formatted}] {text}\")\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "def save_formatted_transcript(transcript, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for entry in transcript:\n",
    "            start_time = entry['start']\n",
    "            duration = entry['duration']\n",
    "            text = entry['text']\n",
    "            end_time = start_time + duration\n",
    "            \n",
    "            start_formatted = format_timestamp(start_time)\n",
    "            end_formatted = format_timestamp(end_time)\n",
    "            \n",
    "            f.write(f\"[{start_formatted} - {end_formatted}] {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>1. AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Channel:</strong> AMD</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Published:</strong> 2024-06-03T03:12:08Z</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Description:</strong> The Future of High-Performance Computing in the AI Era Join us as Dr. Lisa Su delivers the Computex ...</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/MCi8jgALPYA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x252ab0180d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from IPython.display import YouTubeVideo, display, HTML\n",
    "\n",
    "# Replace with your actual API key\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "def youtube_search(query, max_results=1):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=youtube_api_key)\n",
    "\n",
    "    try:\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            part=\"id,snippet\",\n",
    "            maxResults=max_results\n",
    "        ).execute()\n",
    "\n",
    "        videos = []\n",
    "\n",
    "        for search_result in search_response.get(\"items\", []):\n",
    "            video = {\n",
    "                \"title\": search_result[\"snippet\"][\"title\"],\n",
    "                \"description\": search_result[\"snippet\"][\"description\"],\n",
    "                \"video_id\": search_result[\"id\"][\"videoId\"],\n",
    "                \"publish_time\": search_result[\"snippet\"][\"publishTime\"],\n",
    "                \"channel_title\": search_result[\"snippet\"][\"channelTitle\"]\n",
    "            }\n",
    "            videos.append(video)\n",
    "\n",
    "        return videos\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "        return None\n",
    "\n",
    "# Function to display search results\n",
    "def display_results(results):\n",
    "    for i, video in enumerate(results, 1):\n",
    "        display(HTML(f\"<h3>{i}. {video['title']}</h3>\"))\n",
    "        display(HTML(f\"<p><strong>Channel:</strong> {video['channel_title']}</p>\"))\n",
    "        display(HTML(f\"<p><strong>Published:</strong> {video['publish_time']}</p>\"))\n",
    "        display(HTML(f\"<p><strong>Description:</strong> {video['description'][:100]}...</p>\"))\n",
    "        display(YouTubeVideo(video['video_id'], width=400, height=300))\n",
    "        display(HTML(\"<hr>\"))\n",
    "\n",
    "# Example usage\n",
    "search_query = \"Lisa Su Computex Keynote\"\n",
    "results = youtube_search(search_query)\n",
    "\n",
    "if results:\n",
    "    display_results(results)\n",
    "else:\n",
    "    print(\"No results found or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playback YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "from pytube import YouTube\n",
    "import time\n",
    "\n",
    "def download_youtube_video(video_id, temp_dir=None):\n",
    "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    \n",
    "    try:\n",
    "        yt = YouTube(video_url)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "\n",
    "        # Create a temporary directory\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # Download the video\n",
    "        print(\"Downloading video...\")\n",
    "        video_path = stream.download(output_path=temp_dir)\n",
    "        print(f\"Video downloaded to: {video_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading and trimming: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return temp_dir, video_path\n",
    "\n",
    "\n",
    "def trim_youtube_video(video_path, start_time, end_time, temp_dir=None):\n",
    "    try:\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # Trim the video using ffmpeg\n",
    "        output_path = os.path.join(temp_dir, 'video.mp4')\n",
    "        duration = end_time - start_time\n",
    "        ffmpeg_command = f'ffmpeg -i \"{video_path}\" -ss {start_time} -t {duration} -c copy \"{output_path}\"'\n",
    "\n",
    "        print(\"Trimming video...\")\n",
    "        print(f\"FFmpeg command: {ffmpeg_command}\")\n",
    "        result = subprocess.run(ffmpeg_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"FFmpeg error: {result.stderr}\")\n",
    "            raise Exception(\"FFmpeg failed to trim the video\")\n",
    "\n",
    "        print(f\"Trimmed video saved to: {output_path}\")\n",
    "\n",
    "        if not os.path.exists(output_path):\n",
    "            raise FileNotFoundError(f\"Trimmed video file not found: {output_path}\")\n",
    "\n",
    "        return temp_dir, output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading and trimming: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def play_youtube_video(video_path, duration):\n",
    "    try:\n",
    "        # Convert to absolute path\n",
    "        abs_video_path = os.path.abspath(video_path)\n",
    "        print(f\"Absolute video path: {abs_video_path}\")\n",
    "\n",
    "        if not os.path.exists(abs_video_path):\n",
    "            raise FileNotFoundError(f\"Video file not found: {abs_video_path}\")\n",
    "\n",
    "        print(f\"Attempting to play video: {abs_video_path}\")\n",
    "\n",
    "        # Play the trimmed video with the default player\n",
    "        if os.name == 'nt':  # For Windows\n",
    "            print(\"Using subprocess method...\")\n",
    "            subprocess.Popen(['start', '', abs_video_path], shell=True)\n",
    "        else:\n",
    "            raise NotImplementedError(\"This script currently supports Windows only\")\n",
    "\n",
    "        print(\"Default player command executed.\")\n",
    "\n",
    "        # Wait for the duration of the video\n",
    "        print(f\"Waiting for {duration} seconds...\")\n",
    "        time.sleep(duration + 2)  # Add a small buffer\n",
    "\n",
    "        print(\"Playback duration completed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while playing: {e}\")\n",
    "\n",
    "    print(\"Function play_youtube_video completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory created: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp62xsxhhv\n",
      "Trimming segment 1/3...\n",
      "FFmpeg command: ffmpeg -i \"path/to/your/video.mp4\" -ss 10 -t 10 -c copy \"C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp62xsxhhv\\segment_0.mp4\"\n",
      "FFmpeg error: ffmpeg version 7.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[in#0 @ 0000025117e45040] Error opening input: No such file or directory\n",
      "Error opening input file path/to/your/video.mp4.\n",
      "Error opening input files: No such file or directory\n",
      "\n",
      "An error occurred while trimming and stitching: FFmpeg failed to trim segment 1\n",
      "Video processing failed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "def trim_and_stitch_youtube_video(video_path, time_segments, output_path, temp_dir=None):\n",
    "    try:\n",
    "        assert os.path.isfile(file_path), f\"ERROR: {video_path} doesn't exist\"\n",
    "\n",
    "        if not temp_dir:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            print(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "        # List to store paths of trimmed segments\n",
    "        trimmed_segments = []\n",
    "\n",
    "        # Trim each segment\n",
    "        for i, (start_time, end_time) in enumerate(time_segments):\n",
    "            segment_path = os.path.join(temp_dir, f'segment_{i}.mp4')\n",
    "            duration = end_time - start_time\n",
    "            ffmpeg_command = f'ffmpeg -i \"{video_path}\" -ss {start_time} -t {duration} -c copy \"{segment_path}\"'\n",
    "\n",
    "            print(f\"Trimming segment {i+1}/{len(time_segments)}...\")\n",
    "            print(f\"FFmpeg command: {ffmpeg_command}\")\n",
    "            result = subprocess.run(ffmpeg_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                print(f\"FFmpeg error: {result.stderr}\")\n",
    "                raise Exception(f\"FFmpeg failed to trim segment {i+1}\")\n",
    "\n",
    "            trimmed_segments.append(segment_path)\n",
    "\n",
    "        # Create a file list for concatenation\n",
    "        list_file_path = os.path.join(temp_dir, 'file_list.txt')\n",
    "        with open(list_file_path, 'w') as list_file:\n",
    "            for segment in trimmed_segments:\n",
    "                list_file.write(f\"file '{segment}'\\n\")\n",
    "\n",
    "        # Concatenate all segments\n",
    "        concat_command = f'ffmpeg -f concat -safe 0 -i \"{list_file_path}\" -c copy \"{output_path}\" -y'\n",
    "        print(\"Concatenating segments...\")\n",
    "        print(f\"FFmpeg command: {concat_command}\")\n",
    "        result = subprocess.run(concat_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"FFmpeg error: {result.stderr}\")\n",
    "            raise Exception(\"FFmpeg failed to concatenate the segments\")\n",
    "\n",
    "        print(f\"Final video saved to: {output_path}\")\n",
    "\n",
    "        if not os.path.exists(output_path):\n",
    "            raise FileNotFoundError(f\"Final video file not found: {output_path}\")\n",
    "\n",
    "        return temp_dir, output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trimming and stitching: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage:\n",
    "video_path = \"path/to/your/video.mp4\"\n",
    "time_segments = [(10, 20), (30, 40), (50, 60)]  # List of (start_time, end_time) tuples\n",
    "output_path = \"path/to/output/final_video.mp4\"\n",
    "\n",
    "temp_dir, final_video_path = trim_and_stitch_youtube_video(video_path, time_segments, output_path)\n",
    "\n",
    "if temp_dir and final_video_path:\n",
    "    print(\"Video processing completed successfully!\")\n",
    "    # Don't forget to clean up the temp_dir when you're done\n",
    "else:\n",
    "    print(\"Video processing failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video...\n",
      "Video downloaded to: c:\\Users\\kovtchar\\Work\\gaia\\notebooks\\./AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\n",
      "Trimming video...\n",
      "FFmpeg command: ffmpeg -i \"c:\\Users\\kovtchar\\Work\\gaia\\notebooks\\./AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\" -ss 45 -t 22 -c copy \"./video.mp4\"\n"
     ]
    }
   ],
   "source": [
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "youtube_url = 'https://www.youtube.com/watch?v=MCi8jgALPYA'\n",
    "\n",
    "start_time = 45  # Start time in seconds\n",
    "end_time = 67    # End time in seconds\n",
    "\n",
    "temp_dir, video_path = download_youtube_video(youtube_url, './')\n",
    "temp_dir, video_path = trim_youtube_video(video_path, start_time, end_time, './')\n",
    "# video_path = \"C:\\\\Users\\\\kovtchar\\\\Work\\\\gaia\\\\notebooks\\\\video.mp4\"\n",
    "play_youtube_video(video_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Video ID: MCi8jgALPYA\n",
      "[00:00:36 - 00:00:41] We will now proceed to the AMD opening keynote speech.\n",
      "[00:00:41 - 00:00:45] TAITRA chairman James Huang will help us introduce our keynote speaker.\n",
      "[00:00:45 - 00:00:47] Please once again welcome James to the stage.\n",
      "[00:00:57 - 00:01:00] Now the moment you have been waiting for.\n",
      "[00:01:00 - 00:01:08] As chair and CEO of AMD, Dr Lisa Su has led a company's transformation into a powerhouse\n",
      "[00:01:08 - 00:01:11] of high performance computing.\n",
      "[00:01:11 - 00:01:17] Under her visionary leadership, AMD has achieved remarkable success.\n",
      "[00:01:17 - 00:01:27] Dr Su was recently named the 2024 chief executive of the year by chief executive magazine.\n",
      "[00:01:27 - 00:01:34] Recognized for her role in one of the most spectacular achievements in technology sector.\n",
      "[00:01:34 - 00:01:39] Dr Su's influence extends beyond AMD.\n",
      "[00:01:39 - 00:01:46] She has been a key advocate for the integration of AI across industries.\n",
      "[00:01:46 - 00:01:49] Emphasizing its transformative power.\n",
      "[00:01:49 - 00:01:56] Her commitment to innovation and collaboration is evident in her leadership style, which\n",
      "[00:01:56 - 00:02:02] focuses on the development of cutting edge solutions while fostering an inclusive and\n",
      "[00:02:02 - 00:02:06] forward looking company culture.\n",
      "[00:02:06 - 00:02:14] Now, on behalf of Computex, I am very pleased to welcome our old friend, Lisa.\n",
      "[00:02:14 - 00:02:17] But we are going to share a video from AMD first.\n",
      "[00:02:24 - 00:02:28] AMD makes the limitless potential of AI possible\n",
      "[00:02:28 - 00:02:31] from AI PCs to edge to cloud.\n",
      "[00:02:31 - 00:02:37] Powered by some of the most advanced GPUs, CPUs and NPUs on the planet\n",
      "[00:02:39 - 00:02:44] And enabled by an open software approach that's accessible to all.\n",
      "[00:02:44 - 00:02:50] Together with our partners, AI from AMD helps make more imagination possible.\n",
      "[00:02:50 - 00:02:56] Innovation, breakthroughs and healing possible.\n",
      "[00:02:56 - 00:03:01] Peace of mind and thrills possible.\n",
      "[00:03:01 - 00:03:04] The impossible is now possible.\n",
      "[00:03:23 - 00:03:32] Ladies and gentlemen, please join me in welcoming Dr Lisa Su, chair and CEO of AMD.\n",
      "[00:03:36 - 00:03:41] Thank you Lisa, thank you so much.\n",
      "[00:03:41 - 00:03:43] Thank you, thank you.\n",
      "[00:03:47 - 00:03:48] Good morning.\n",
      "[00:03:58 - 00:04:04] Thank you James for that very, very warm introduction and welcome to everyone joining us today in\n",
      "[00:04:04 - 00:04:11] Taipei and from around the world as we open Computex 2024.\n",
      "[00:04:11 - 00:04:16] Every year Computex is such an important event for our industry as we bring together all\n",
      "[00:04:16 - 00:04:21] members of the ecosystem to share new products, to talk about new innovations and really discuss\n",
      "[00:04:21 - 00:04:24] the future of technology.\n",
      "[00:04:24 - 00:04:26] But this year is even more special.\n",
      "[00:04:26 - 00:04:31] With the rapid innovation around AI and all of the new technology everywhere, it is actually\n",
      "[00:04:31 - 00:04:36] the biggest and the most important Computex ever and I'm so honored to be here to open\n",
      "[00:04:36 - 00:04:37] the show.\n",
      "[00:04:37 - 00:04:41] Now we have a lot of new products and news to share today so let's just go ahead and\n",
      "[00:04:41 - 00:04:43] get started.\n",
      "[00:04:43 - 00:04:48] Now at AMD we're all about pushing the envelope in high performance and adaptive computing\n",
      "[00:04:48 - 00:04:52] to help solve the world's most important challenges.\n",
      "[00:04:52 - 00:04:58] From cloud and enterprise data centers to 5G networks to healthcare, industrial, automotive,\n",
      "[00:04:58 - 00:05:06] PCs, gaming and AI, AMD technology is everywhere, powering the lives of billions of people every day.\n",
      "[00:05:07 - 00:05:13] AI is our number one priority and we're at the beginning of an incredibly exciting time\n",
      "[00:05:13 - 00:05:19] for the industry as AI transforms virtually every business, improves our quality of life\n",
      "[00:05:19 - 00:05:22] and reshapes every part of the computing market.\n",
      "[00:05:22 - 00:05:27] AMD is uniquely positioned to power the end-to-end infrastructure that will define the AI computing\n",
      "[00:05:27 - 00:05:33] era from massive cloud servers and enterprise clusters to the next generation of AI enabled\n",
      "[00:05:33 - 00:05:37] intelligent embedded devices and PCs.\n",
      "[00:05:37 - 00:05:43] Now to deliver all of these leadership AI solutions we're focused on three priorities.\n",
      "[00:05:43 - 00:05:48] First it's delivering a broad portfolio of high performance energy efficient compute\n",
      "[00:05:48 - 00:05:55] engines for AI training and inference including CPUs, GPUs and NPUs.\n",
      "[00:05:55 - 00:06:01] Second it's about enabling an open and proven and a developer friendly ecosystem that really\n",
      "[00:06:01 - 00:06:06] ensures that all of the leading AI frameworks, libraries and models are fully enabled on\n",
      "[00:06:06 - 00:06:08] AMD hardware.\n",
      "[00:06:08 - 00:06:11] And third it's about partnership.\n",
      "[00:06:11 - 00:06:17] It's really about co-innovating with our partners including the largest cloud, OEM, software\n",
      "[00:06:17 - 00:06:24] and AI companies in the world as we work together to bring the best AI solutions to the market.\n",
      "[00:06:24 - 00:06:28] Now today we're going to talk about a lot of new technologies and products including\n",
      "[00:06:28 - 00:06:33] our brand new Zen 5 core which is the highest performance and most energy efficient core\n",
      "[00:06:33 - 00:06:40] we've ever built and our next generation XDNA 2 NPU core that enables leadership performance\n",
      "[00:06:40 - 00:06:43] and capabilities for AI PCs.\n",
      "[00:06:43 - 00:06:48] And we're also going to be joined by a number of our partners as we launch our new Ryzen\n",
      "[00:06:48 - 00:06:53] notebook and desktop processors and preview our data center CPU and GPU portfolio for\n",
      "[00:06:53 - 00:06:56] this exciting AI world.\n",
      "[00:06:56 - 00:06:59] So let's go ahead and get started with gaming PCs.\n",
      "[00:06:59 - 00:07:03] Now at AMD we love gaming.\n",
      "[00:07:03 - 00:07:07] Hundreds of millions of gamers everywhere use AMD technology.\n",
      "[00:07:07 - 00:07:13] From the latest Sony and Microsoft consoles to the highest end gaming PCs to new handheld\n",
      "[00:07:13 - 00:07:18] devices like the Steam Deck, Legion Go and ROG Ally.\n",
      "[00:07:18 - 00:07:23] Today I'm excited to show you what's next for PC gaming with Ryzen.\n",
      "[00:07:23 - 00:07:29] Our new Ryzen 9000 CPUs are the world's fastest consumer PC processors, bringing our new\n",
      "[00:07:29 - 00:07:36] Zen 5 core to the AM5 platform with support for the latest IO and memory technologies\n",
      "[00:07:36 - 00:07:39] including PCIe 5 and DDR5.\n",
      "[00:07:39 - 00:07:43] I'm happy to show you now our brand new Zen 5 core.\n",
      "[00:07:43 - 00:07:48] Zen 5 is actually the next big step in high performance CPUs.\n",
      "[00:07:48 - 00:07:54] It's a grounds-up design that's extremely high performance and also incredibly energy-efficient.\n",
      "[00:07:54 - 00:08:00] You're going to see Zen 5 everywhere, from supercomputers to data centers and PCs.\n",
      "[00:08:00 - 00:08:05] And when you look at the technology behind this, we have so much new technology.\n",
      "[00:08:05 - 00:08:09] We have a new parallel dual pipeline front end and what this does is it improves branch\n",
      "[00:08:09 - 00:08:13] prediction accuracy and reduces latency.\n",
      "[00:08:13 - 00:08:19] It also enables us to deliver much more performance for every clock cycle.\n",
      "[00:08:19 - 00:08:24] We also designed Zen 5 with a wider CPU engine and instruction window to run more instructions\n",
      "[00:08:24 - 00:08:28] in parallel for leadership compute throughput and efficiency.\n",
      "[00:08:28 - 00:08:34] As a result, compared to Zen 4, we get double the instruction bandwidth, double the data\n",
      "[00:08:34 - 00:08:39] bandwidth between the cache and floating point unit, and double the AI performance with full\n",
      "[00:08:39 - 00:08:42] AVX-512 throughput.\n",
      "[00:08:42 - 00:08:46] All of this comes together in the product in Ryzen 9000 series, and we're delivering\n",
      "[00:08:46 - 00:08:54] an average of 16% higher IPC across a broad range of application benchmarks and games\n",
      "[00:08:54 - 00:08:58] compared to Zen 4.\n",
      "[00:08:58 - 00:09:03] So now let me show you the top of the line Ryzen 9 9950X for the very first time.\n",
      "[00:09:07 - 00:09:12] There you go.\n",
      "[00:09:12 - 00:09:23] We have 16 Zen 5 cores, 32 threads, up to 5.67 gigahertz boost, a large 80 megabyte cache\n",
      "[00:09:23 - 00:09:26] at 170 watt TDP.\n",
      "[00:09:26 - 00:09:31] This is the fastest consumer CPU in the world.\n",
      "[00:09:37 - 00:09:40] Okay, so let's take a look at some of the performance.\n",
      "[00:09:40 - 00:09:45] So when you compare it to the competition, the 9950X delivers significantly more compute\n",
      "[00:09:45 - 00:09:50] performance across a broad suite of content creation software.\n",
      "[00:09:50 - 00:09:55] In some of them, you actually see like Blender that take advantage of the AVX-512 instruction\n",
      "[00:09:55 - 00:10:01] throughput, we're actually seeing up to 56% faster than the competition.\n",
      "[00:10:01 - 00:10:07] And in 1080p gaming, we know all of our fans love gaming, the 9950X delivers best in class\n",
      "[00:10:07 - 00:10:12] gaming performance across a wide range of popular games.\n",
      "[00:10:12 - 00:10:16] Now with desktops, we know that enthusiasts want to have an infrastructure that let you\n",
      "[00:10:16 - 00:10:22] upgrade across multiple product generations, and with Ryzen, we've done just that.\n",
      "[00:10:22 - 00:10:29] Our original Ryzen platform, Socket AM4, launched in 2016, and now we're approaching the ninth\n",
      "[00:10:29 - 00:10:37] year, and we have 145 CPUs and APUs across 11 different product families in Socket AM4.\n",
      "[00:10:37 - 00:10:39] And we're actually still launching new products.\n",
      "[00:10:39 - 00:10:44] We actually have a few Ryzen 5000 CPUs that are coming next month.\n",
      "[00:10:44 - 00:10:49] And we're taking this exact same strategy with Socket AM5, which we now plan on supporting\n",
      "[00:10:49 - 00:10:55] through 2027 and beyond, so you're going to see AM5 processors from us for many, many\n",
      "[00:10:55 - 00:10:57] years to come.\n",
      "[00:10:57 - 00:11:02] Now, in addition to the top of the stack, Ryzen 9950X, we're also announcing the 12-,\n",
      "[00:11:02 - 00:11:07] 8-, and 6-core versions that will bring the leadership performance of Zen 5 to mainstream\n",
      "[00:11:07 - 00:11:11] price points, and all of these go on sale in July.\n",
      "[00:11:19 - 00:11:23] So now let's shift gears from desktops to laptops, and there's going to be a lot of\n",
      "[00:11:23 - 00:11:26] discussion about laptops at Computex this year.\n",
      "[00:11:26 - 00:11:32] AMD has been actually leading the transition to AI PCs since we introduced our first generation\n",
      "[00:11:32 - 00:11:34] of Ryzen AI in January last year.\n",
      "[00:11:34 - 00:11:39] Now, AI is actually revolutionizing the way we interact with PCs.\n",
      "[00:11:39 - 00:11:44] It enables more intelligent, personalized experiences that will make the PC an even\n",
      "[00:11:44 - 00:11:48] more essential part of our daily lives.\n",
      "[00:11:48 - 00:11:53] AI PCs enable many new experiences that were simply not possible before.\n",
      "[00:11:53 - 00:11:59] These are things like real-time translations that will allow us to collaborate in new ways,\n",
      "[00:11:59 - 00:12:04] things like generative AI capabilities that accelerate content creation, and also we each\n",
      "[00:12:04 - 00:12:09] want our own customized digital assistant that really will help us decide what we need\n",
      "[00:12:09 - 00:12:12] to do and what we should do next.\n",
      "[00:12:12 - 00:12:17] To enable all of this, we actually need much, much better AI hardware, and that's why we're\n",
      "[00:12:17 - 00:12:22] so excited to announce today our third gen Ryzen AI processors.\n",
      "[00:12:22 - 00:12:28] Our new Ryzen AI series actually is a significant increase in computing AI performance and sets\n",
      "[00:12:28 - 00:12:32] the bar for what a Copilot PC should do.\n",
      "[00:12:32 - 00:12:34] Thank you, Drew.\n",
      "[00:12:34 - 00:12:35] Here we go.\n",
      "[00:12:35 - 00:12:36] This is Strix.\n",
      "[00:12:43 - 00:12:49] Strix is our next-generation processor for ultra-thin and premium notebooks, and it combines\n",
      "[00:12:49 - 00:13:01] our new Zen 5 CPU, faster RDNA 3.5 graphics, and the new XDNA 2 NPU.\n",
      "[00:13:01 - 00:13:04] Thank you.\n",
      "[00:13:04 - 00:13:09] And when you look at what we have, it really is all of the best technology on one chip.\n",
      "[00:13:09 - 00:13:14] We have a new NPU that delivers an industry-leading 50 TOPS.\n",
      "[00:13:14 - 00:13:20] We're going to talk about TOPS a lot today, 50 TOPS of compute that can power new AI experiences\n",
      "[00:13:20 - 00:13:22] at very low power.\n",
      "[00:13:22 - 00:13:27] We have our new Zen 5 core that enables all the compute performance for ultra-thin notebooks,\n",
      "[00:13:27 - 00:13:32] and we have faster RDNA 3.5 graphics that really brings the best-in-class application\n",
      "[00:13:32 - 00:13:37] acceleration as well as console-level gaming to notebooks.\n",
      "[00:13:37 - 00:13:38] Now we have a couple of SKUs.\n",
      "[00:13:38 - 00:13:47] The flagship Ryzen 9 HX 370 has 12 Zen 5 cores, 24 threads, 36 megabytes of cache, the industry's\n",
      "[00:13:47 - 00:13:52] most integrated NPU, and our latest RDNA graphics.\n",
      "[00:13:52 - 00:13:55] Strix is simply the best mobile CPU.\n",
      "[00:13:55 - 00:14:00] So let me talk a little bit about what's special in this new NPU.\n",
      "[00:14:00 - 00:14:06] NPUs are really new, and they're really there for all of these AI applications and workloads.\n",
      "[00:14:06 - 00:14:13] Now compared to our prior generation, XDNA 2 features a large array of 32 AI tiles with\n",
      "[00:14:13 - 00:14:16] double the multitasking performance.\n",
      "[00:14:16 - 00:14:20] It's also an extremely efficient architecture that delivers up to two times better energy\n",
      "[00:14:20 - 00:14:26] efficiency of our prior generation when running Gen AI workloads, and if you look at the performance\n",
      "[00:14:26 - 00:14:31] of Strix compared to other chips in the market, and there are a lot of chips that are coming out with\n",
      "[00:14:31 - 00:14:40] new NPUs, XDNA delivers the highest performance, leadership 50 TOPS of INT8 AI performance.\n",
      "[00:14:47 - 00:14:53] And what this means is that third-gen Ryzen AI will deliver the best NPU-powered experiences\n",
      "[00:14:53 - 00:14:55] in a Copilot+ PC.\n",
      "[00:14:55 - 00:15:00] But let me just go a little bit deeper so you understand the technology.\n",
      "[00:15:00 - 00:15:06] Every NPU is actually not the same when it comes to generative AI capabilities.\n",
      "[00:15:06 - 00:15:10] Different NPUs actually support different data types, and that says something about\n",
      "[00:15:10 - 00:15:14] the accuracy and the performance of the devices.\n",
      "[00:15:14 - 00:15:19] So for generative AI, 16-bit floating-point data types are great for accuracy, but they\n",
      "[00:15:19 - 00:15:25] actually sacrifice performance, and the current standard for NPUs is actually 8-bit integer\n",
      "[00:15:25 - 00:15:26] data types.\n",
      "[00:15:26 - 00:15:30] They prioritize performance, but they sacrifice accuracy.\n",
      "[00:15:30 - 00:15:35] And what this means is that developers really have a tough choice to make between offering\n",
      "[00:15:35 - 00:15:40] either a more accurate solution or a more performance solution.\n",
      "[00:15:40 - 00:15:47] Now XDNA 2 is the first NPU to support block 16-bit floating-point, and what that means\n",
      "[00:15:47 - 00:15:54] is block FP16 actually combines the accuracy of 16-bit data with the performance of 8-bit data.\n",
      "[00:15:56 - 00:16:01] This represents a huge leap forward in AI capability, and enables developers to run\n",
      "[00:16:01 - 00:16:07] complex models natively without any quantization steps at full speed, and what that means is\n",
      "[00:16:07 - 00:16:10] with no compromise.\n",
      "[00:16:10 - 00:16:13] And so let me show you what this looks like when you look at the example.\n",
      "[00:16:13 - 00:16:18] These are three images that are generated by the popular Stable Diffusion XL Turbo Gen\n",
      "[00:16:18 - 00:16:19] AI model.\n",
      "[00:16:19 - 00:16:25] We use the same prompt with no quantization or retraining for all three, and the only\n",
      "[00:16:25 - 00:16:27] difference is actually the data type.\n",
      "[00:16:27 - 00:16:32] So int 8 is on the left, which is what most NPUs are using.\n",
      "[00:16:32 - 00:16:38] Block FP16 is in the middle, which is what XDNA 2 has, and then FP16 is on the right,\n",
      "[00:16:38 - 00:16:41] which is the more traditional format.\n",
      "[00:16:41 - 00:16:46] And as you can see, the two 16-bit images look much better with no real differences\n",
      "[00:16:46 - 00:16:53] between the two, and it is only because our NPU supports that block FP16 that \n",
      "[00:16:53 - 00:16:58] Ryzen AI is capable of generating the significantly better images in the same time that it takes\n",
      "[00:16:58 - 00:17:02] to generate the lower quality INT8 images.\n",
      "[00:17:02 - 00:17:08] And this is just an example of why we believe that NPUs with the right data types are the\n",
      "[00:17:08 - 00:17:14] best for the next generation PCs, and this is why we believe that XDNA 2 is the best\n",
      "[00:17:14 - 00:17:17] NPU in the industry.\n",
      "[00:17:17 - 00:17:22] Now Microsoft is a great partner and is really leading the AI era, and we've been working\n",
      "[00:17:22 - 00:17:28] very, very closely with them to bring Copilot+ PCs to market with Strix.\n",
      "[00:17:28 - 00:17:33] So to hear more about the work we're doing together, I'd like to welcome Pavan Davuluri,\n",
      "[00:17:33 - 00:17:37] Corporate Vice President, Windows Devices at Microsoft, to the stage.\n",
      "[00:17:43 - 00:17:46] Pavan, so wonderful to see you.\n",
      "[00:17:46 - 00:17:48] Thank you so much for joining me here in Taipei.\n",
      "[00:17:48 - 00:17:49] Absolutely.\n",
      "[00:17:50 - 00:17:53] You know, I know it's been a super busy time for you guys, so much is going on.\n",
      "[00:17:53 - 00:17:56] Can you tell us a little bit about what's been going on?\n",
      "[00:17:56 - 00:17:59] Thank you, Lisa, for having us here today.\n",
      "[00:17:59 - 00:18:02] It is an honor to be here at Computex with all of you.\n",
      "[00:18:02 - 00:18:06] It has been a really busy couple of weeks for us here at Microsoft.\n",
      "[00:18:06 - 00:18:12] We announced a new category of PCs built for AI, the Copilot+ PCs.\n",
      "[00:18:12 - 00:18:17] To realize the full power of AI in a PC, we re-engineered the entire system from chip through\n",
      "[00:18:17 - 00:18:19] every layer of Windows.\n",
      "[00:18:19 - 00:18:25] These are the fastest, most performant, most intelligent PCs, and we are thrilled to partner\n",
      "[00:18:25 - 00:18:29] with AMD on Strix-based Copilot+ PCs.\n",
      "[00:18:29 - 00:18:30] Thank you.\n",
      "[00:18:30 - 00:18:31] We are, too.\n",
      "[00:18:31 - 00:18:35] Lisa, I truly believe we're at an inflection point here where AI is making computing radically\n",
      "[00:18:35 - 00:18:41] more intelligent and personal, and we've collaborated with AMD since day one on this, and I'm very\n",
      "[00:18:41 - 00:18:42] excited about that.\n",
      "[00:18:43 - 00:18:49] Pavan, there's no question Microsoft and you and your team have really led this whole AI\n",
      "[00:18:49 - 00:18:51] PC era.\n",
      "[00:18:51 - 00:18:53] We've always talked about user experiences.\n",
      "[00:18:53 - 00:18:57] Can you talk a little bit about what you were thinking with Copilot PCs and this integration\n",
      "[00:18:57 - 00:19:01] between operating systems, hardware, and software?\n",
      "[00:19:01 - 00:19:03] Sure, absolutely.\n",
      "[00:19:03 - 00:19:07] The first thing I think customers will see with Copilot+ PCs is that they're simply\n",
      "[00:19:07 - 00:19:10] outstanding PCs.\n",
      "[00:19:10 - 00:19:14] These devices will have leading performance and best-in-class battery life, and every\n",
      "[00:19:14 - 00:19:18] app will work great on these machines.\n",
      "[00:19:18 - 00:19:21] Now for those next-gen AI experiences, how about we just take a look, Lisa?\n",
      "[00:19:21 - 00:19:22] Sounds good.\n",
      "[00:20:47 - 00:20:48] Fantastic, Pavan.\n",
      "[00:20:48 - 00:20:54] So what you just saw there, those devices and those experiences have on-device AI that\n",
      "[00:20:54 - 00:20:58] is powerful enough to keep up with all of the experiences we want and efficient enough\n",
      "[00:20:58 - 00:21:00] to be always running.\n",
      "[00:21:00 - 00:21:04] For example, you just saw Recall that helps users instantly find anything on their PC,\n",
      "[00:21:04 - 00:21:09] and that's only possible because we can semantically index content in the background, which requires\n",
      "[00:21:09 - 00:21:12] always-on high-performance AI.\n",
      "[00:21:12 - 00:21:16] Cocreator lets you generate high-quality images by drawing and paint, and we can do\n",
      "[00:21:16 - 00:21:19] that with fast on-device image generation.\n",
      "[00:21:19 - 00:21:25] We have live captions, which will translate your audio in real time on a PC, switching\n",
      "[00:21:25 - 00:21:27] automatically between languages, in fact.\n",
      "[00:21:27 - 00:21:31] But I truly think what you just saw, Lisa, is just the beginning.\n",
      "[00:21:31 - 00:21:36] We built this thing called the Windows Copilot Runtime, which is effectively our library\n",
      "[00:21:36 - 00:21:44] of APIs to let developers access new AI capabilities built into Windows, and those capabilities\n",
      "[00:21:44 - 00:21:49] are also backed by Microsoft's responsibilities around responsible AI, and I truly think we\n",
      "[00:21:49 - 00:21:54] are going to be blown by what partners build in addition to what Microsoft and AMD is bringing.\n",
      "[00:21:54 - 00:21:55] I completely agree.\n",
      "[00:21:55 - 00:22:00] I think this is really bringing the entire ecosystem together, and one of the things,\n",
      "[00:22:00 - 00:22:04] Pavan, that you and I have talked a lot about is the importance of the hardware, and it's\n",
      "[00:22:04 - 00:22:10] all about how do we give you enough power such that you can run these Copilot+ PCs\n",
      "[00:22:10 - 00:22:12] So can you talk a little bit about your vision there?\n",
      "[00:22:12 - 00:22:14] Sure, absolutely.\n",
      "[00:22:14 - 00:22:19] With Copilot+ PCs, we want to make it possible to deliver these next-gen AI experiences\n",
      "[00:22:19 - 00:22:23] by using on-device capabilities and do that in concert with the cloud.\n",
      "[00:22:23 - 00:22:29] On-device AI really for us means faster response times, better privacy, lower costs, but that\n",
      "[00:22:29 - 00:22:35] That means running models that have billions of parameters in them on PC hardware.\n",
      "[00:22:35 - 00:22:39] Compared to traditional PCs even from just a few years ago, we're talking 20 times the\n",
      "[00:22:39 - 00:22:44] performance and up to 100 times the efficiency for AI workloads, and to make that possible,\n",
      "[00:22:44 - 00:22:50] every Copilot+ PC needs an NPU that's at least capable of 40 TOPS, and we're deeply\n",
      "[00:22:50 - 00:22:52] grateful for the close partnership with AMD.\n",
      "[00:22:52 - 00:22:56] We are thrilled that Strix Point's NPU delivers an incredible 50 TOPS.\n",
      "[00:22:56 - 00:22:59] That is super, super powerful for us.\n",
      "[00:22:59 - 00:23:01] We wanted to give you more.\n",
      "[00:23:01 - 00:23:03] We're always ready.\n",
      "[00:23:03 - 00:23:07] The powerful thing with that, of course, it means we're efficiently delivering these Copilot+\n",
      "[00:23:07 - 00:23:12] experiences, but also gives us headroom for the next generation of AI, and we're at\n",
      "[00:23:12 - 00:23:13] the start of that runway.\n",
      "[00:23:13 - 00:23:18] Of course, the Copilot+ PCs complement that power of the NPU with at least 16 gigabytes\n",
      "[00:23:18 - 00:23:24] of RAM and 256 gigabytes of SSD storage, so I truly think these devices are built for\n",
      "[00:23:24 - 00:23:26] the era of AI that's coming.\n",
      "[00:23:26 - 00:23:32] One of the things I can share, Pavan, is as we talk, you guys are always pushing us to\n",
      "[00:23:32 - 00:23:33] give you more.\n",
      "[00:23:33 - 00:23:34] You're always saying, more TOPS, Lisa.\n",
      "[00:23:34 - 00:23:35] More TOPS.\n",
      "[00:23:35 - 00:23:38] What are you doing with all those TOPS?\n",
      "[00:23:38 - 00:23:40] What's your vision for the future?\n",
      "[00:23:40 - 00:23:42] I do remember those conversations, Lisa.\n",
      "[00:23:42 - 00:23:46] By the way, it takes a lot of die area, just so you know.\n",
      "[00:23:46 - 00:23:48] I can only imagine.\n",
      "[00:23:48 - 00:23:52] We are deeply excited about those commitments and, quite frankly, the deep collaboration\n",
      "[00:23:52 - 00:23:55] across our teams to go bring that to life.\n",
      "[00:23:55 - 00:24:00] For us, these breakthrough experiences require us to run these billion-parameter models always\n",
      "[00:24:00 - 00:24:05] running on the device, and that requires high-performance NPUs to power them.\n",
      "[00:24:05 - 00:24:09] And really, thanks to our deep partnership, we've been able to seamlessly cross-compile\n",
      "[00:24:09 - 00:24:15] and execute over 40 on-device models on these AMD NPUs, which is very meaningful for us.\n",
      "[00:24:15 - 00:24:19] We took advantage of all of the low-level software and hardware capabilities of the\n",
      "[00:24:19 - 00:24:23] AMD silicon here, so we did not lose any performance nor efficiency.\n",
      "[00:24:23 - 00:24:29] Also, these high-performance NPUs are really the best way to drive overall PC performance.\n",
      "[00:24:29 - 00:24:33] Getting to 50 TOPS, for example, is a quantum leap for us, for sure.\n",
      "[00:24:33 - 00:24:37] And it's really much, much more impactful relative to what you could do with just a\n",
      "[00:24:37 - 00:24:39] CPU or GPU alone.\n",
      "[00:24:39 - 00:24:43] And the other thing that excites me really is that these powerful NPUs then free up the\n",
      "[00:24:43 - 00:24:46] GPUs and the NPUs for workloads where they shine.\n",
      "[00:24:46 - 00:24:49] So I'm excited to see what developers will do with this going forward.\n",
      "[00:24:49 - 00:24:51] We are super excited as well.\n",
      "[00:24:51 - 00:24:52] Thank you, Pavan, for being here.\n",
      "[00:24:52 - 00:24:54] Thank you for your partnership, and thank you for leading the industry.\n",
      "[00:24:54 - 00:24:56] Thank you, thank you, thank you.\n",
      "[00:25:03 - 00:25:07] So in addition to Microsoft, we're also working with all of the leading software\n",
      "[00:25:07 - 00:25:14] developers, including Adobe, Epic Games, SolidWorks, Sony, Zoom, and many others to\n",
      "[00:25:14 - 00:25:17] accelerate the adoption of AI-enabled PC apps.\n",
      "[00:25:17 - 00:25:24] And by the end of 2024, we're on track to have more than 150 ISVs developing for AMD\n",
      "[00:25:24 - 00:25:31] AI platforms across content creation, consumer, gaming, and productivity applications.\n",
      "[00:25:31 - 00:25:36] Now, to give us a look at some of these upcoming Copilot+ PCs, let me welcome our next\n",
      "[00:25:36 - 00:25:41] guest, a very close partner and good friend, Enrique Lores, HP President and CEO.\n",
      "[00:25:49 - 00:25:52] Enrique, thank you so much for being here.\n",
      "[00:25:52 - 00:25:56] It's always fun to talk about what's next with our teams have been working on.\n",
      "[00:25:56 - 00:25:59] Actually, thank you for having me here and congratulations for all the announcements\n",
      "[00:25:59 - 00:26:00] you have made today.\n",
      "[00:26:00 - 00:26:03] There's a lot more to come.\n",
      "[00:26:03 - 00:26:08] Now, Enrique, you and I have talked a lot about the intersection of AI and hybrid work\n",
      "[00:26:08 - 00:26:09] in recent months.\n",
      "[00:26:09 - 00:26:11] What are you seeing in the industry?\n",
      "[00:26:11 - 00:26:16] I think this is actually what makes many of the announcements that we're making today\n",
      "[00:26:16 - 00:26:17] very exciting.\n",
      "[00:26:17 - 00:26:21] It's not only about the technology improvements that we're going to see, which you have explained\n",
      "[00:26:21 - 00:26:22] extremely well.\n",
      "[00:26:22 - 00:26:29] It's about how they are going to be helping employees and companies to meet their goals.\n",
      "[00:26:29 - 00:26:34] What we see today is a significant tension between all of us as companies that want to\n",
      "[00:26:34 - 00:26:40] continue to improve the productivity of our teams and our teams that are looking for increased\n",
      "[00:26:40 - 00:26:46] flexibility, the ability to meet their personal and private goals, and we think that technology\n",
      "[00:26:46 - 00:26:52] and AI can really help to close that bridge because it can help to improve productivity\n",
      "[00:26:52 - 00:26:57] and at the same time give the flexibility that our teams are looking for.\n",
      "[00:26:57 - 00:27:02] We look at AI PCs as the first instantiation of this change.\n",
      "[00:27:02 - 00:27:05] They will be enabling to increase productivity.\n",
      "[00:27:05 - 00:27:09] We are going to talk about some of the new functionalities and you're going to see how\n",
      "[00:27:09 - 00:27:13] unbelievable they are, but at the same time make sure that employees can deliver on their\n",
      "[00:27:13 - 00:27:16] goals and meet their productivity goals.\n",
      "[00:27:16 - 00:27:22] Yeah, and we've talked a lot about how in this hybrid world people are really wanting\n",
      "[00:27:22 - 00:27:23] all of these different features.\n",
      "[00:27:23 - 00:27:25] Can you talk a little bit about that?\n",
      "[00:27:25 - 00:27:30] I think what we have learned during the last years is that what is really critical for\n",
      "[00:27:30 - 00:27:36] all of us that develop the systems that our teams are going to be using is that we co-engineer\n",
      "[00:27:36 - 00:27:37] the solution.\n",
      "[00:27:37 - 00:27:42] It is not anymore about someone developing the software, someone developing the operating\n",
      "[00:27:42 - 00:27:46] system, someone developing the chips, someone developing the hardware.\n",
      "[00:27:46 - 00:27:51] We need to understand what experience we are building and deliver that experience together.\n",
      "[00:27:51 - 00:27:55] And this is something that we started a few years ago and the teams have been learning\n",
      "[00:27:55 - 00:27:59] how to make that happen and how to co-engineer these solutions.\n",
      "[00:27:59 - 00:28:04] And all the products that we have introduced during the last year, especially for example\n",
      "[00:28:04 - 00:28:09] a product we introduced two weeks ago, the Pavilion Aero, show that.\n",
      "[00:28:09 - 00:28:13] And this is going to be even more important as we show the new AI PCs that we are going\n",
      "[00:28:13 - 00:28:15] to be bringing to market.\n",
      "[00:28:15 - 00:28:21] Because we have made an effort to integrate the new processors, the new chips into the\n",
      "[00:28:21 - 00:28:24] solutions that we are going to be bringing together.\n",
      "[00:28:24 - 00:28:29] And we are incredibly excited about the new family of products we will be launching in\n",
      "[00:28:29 - 00:28:30] a few weeks.\n",
      "[00:28:30 - 00:28:32] So I think you have something to show us.\n",
      "[00:28:32 - 00:28:33] Is that right?\n",
      "[00:28:33 - 00:28:34] I hope so.\n",
      "[00:28:34 - 00:28:40] And this is actually the new generation, since we have done it together, we can show it together.\n",
      "[00:28:40 - 00:28:41] That's wonderful.\n",
      "[00:28:46 - 00:28:55] This is the next generation OmniBook, when we integrate the latest Ryzen AI 300 series\n",
      "[00:28:55 - 00:29:01] that as Lisa was saying before, will be the first product that will have 50 TOPS integrated\n",
      "[00:29:01 - 00:29:02] in the device.\n",
      "[00:29:03 - 00:29:09] And performance, as Pavan was saying, is critical because it will enable us to continue to deliver\n",
      "[00:29:09 - 00:29:12] incredible experiences to our customers.\n",
      "[00:29:12 - 00:29:17] If you ask me what I'm more excited about, it's something that is going to be very close\n",
      "[00:29:17 - 00:29:19] to many people in this room.\n",
      "[00:29:19 - 00:29:22] We HP have a very large team here in Taipei.\n",
      "[00:29:22 - 00:29:28] And we spend many hours in video conferences and Zoom calls.\n",
      "[00:29:28 - 00:29:32] And as you can notice, I have a strong Spanish accent.\n",
      "[00:29:32 - 00:29:37] And I know that for the team here, understanding my accent sometimes is difficult.\n",
      "[00:29:37 - 00:29:41] So just imagine that you can get real-time translation.\n",
      "[00:29:41 - 00:29:42] So I will speak my Spanish.\n",
      "[00:29:42 - 00:29:43] That's pretty good.\n",
      "[00:29:43 - 00:29:44] Come on, Enrique.\n",
      "[00:29:44 - 00:29:49] That's going to make a big difference in productivity.\n",
      "[00:29:49 - 00:29:58] No, I think that's, by the way, I think your English is pretty good, Enrique, but I understand.\n",
      "[00:29:58 - 00:30:00] My Chinese also needs to be better.\n",
      "[00:30:01 - 00:30:02] We can help each other.\n",
      "[00:30:02 - 00:30:03] Yes.\n",
      "[00:30:03 - 00:30:04] Look, we love it.\n",
      "[00:30:04 - 00:30:09] I mean, we love the OmniBook and all the work that we've done together with third gen Ryzen AI processors.\n",
      "[00:30:09 - 00:30:14] But let's actually give everyone a preview of GenAI running on OmniBook.\n",
      "[00:30:14 - 00:30:20] So let me show you again the popular Stable Diffusion XL Turbo model, which is generating\n",
      "[00:30:20 - 00:30:26] some high-quality images of locations around Taiwan based on some simple text prompts.\n",
      "[00:30:26 - 00:30:32] So starting with the white cliffs of Taroko Gorge National Park, Sun Moon Lake with nice\n",
      "[00:30:32 - 00:30:37] fall colors, Taipei 101, and then finally the peak of Jade Mountain.\n",
      "[00:30:37 - 00:30:40] All of this is running on the OmniBook.\n",
      "[00:30:40 - 00:30:46] You're seeing it for the first time.\n",
      "[00:30:46 - 00:30:52] And the reason those pictures are so beautiful is because we have a very, very powerful\n",
      "[00:30:52 - 00:30:53] NPU.\n",
      "[00:30:53 - 00:30:54] We've co-engineered the system together.\n",
      "[00:30:54 - 00:30:58] We have the Block FP16 data support that I talked about.\n",
      "[00:30:58 - 00:31:03] And you can see these beautiful photorealistic images almost instantaneously.\n",
      "[00:31:03 - 00:31:09] Yes, so just imagine the productivity this is going to provide to product managers, creatives\n",
      "[00:31:09 - 00:31:12] that are going to start creating their designs.\n",
      "[00:31:12 - 00:31:16] And just with this solution, they will really be able to accelerate that work.\n",
      "[00:31:16 - 00:31:19] So unbelievable progress.\n",
      "[00:31:19 - 00:31:20] Thank you so much, Enrique.\n",
      "[00:31:20 - 00:31:21] Thank you for your partnership.\n",
      "[00:31:21 - 00:31:24] I can't wait for everything that we're going to bring out together.\n",
      "[00:31:24 - 00:31:25] Thank you, Lisa.\n",
      "[00:31:25 - 00:31:26] Great to be here.\n",
      "[00:31:26 - 00:31:27] Thank you.\n",
      "[00:31:27 - 00:31:27] Thank you.\n",
      "[00:31:32 - 00:31:39] So I showed you earlier that third-gen Ryzen AI has the most powerful NPU, but you also\n",
      "[00:31:39 - 00:31:44] need a high-performance CPU and GPU to deliver the best PC experience as possible.\n",
      "[00:31:44 - 00:31:47] So let's take a look at some of that other performance.\n",
      "[00:31:47 - 00:31:55] When we compare Ryzen AI 300 series to all of the latest x86 and ARM CPUs from our competitors,\n",
      "[00:31:55 - 00:32:00] you can see why we say Strix is really the best notebook CPU in the market.\n",
      "[00:32:00 - 00:32:05] Whether you're looking at single-threaded responsiveness, productivity applications,\n",
      "[00:32:05 - 00:32:10] content creation, or multitasking, third-gen Ryzen AI processors deliver significantly\n",
      "[00:32:10 - 00:32:16] more performance, many times often beating the competition by a large double-digit percentage\n",
      "[00:32:16 - 00:32:20] across a broad range of use cases.\n",
      "[00:32:20 - 00:32:24] Now let's welcome another one of AMD's closest partners in the development of Copilot+ PCs.\n",
      "[00:32:25 - 00:32:30] Let's welcome Luca Rossi, president of Lenovo Intelligent Devices Group.\n",
      "[00:32:33 - 00:32:36] Hey, good morning, Lisa.\n",
      "[00:32:36 - 00:32:37] Wonderful to see you, Luca.\n",
      "[00:32:37 - 00:32:40] Thank you so much for joining us today.\n",
      "[00:32:40 - 00:32:44] We so appreciate the partnership, and Lenovo and AMD are doing so much together.\n",
      "[00:32:44 - 00:32:45] Yeah.\n",
      "[00:32:45 - 00:32:48] Thanks for having me, Lisa.\n",
      "[00:32:48 - 00:32:52] And strong partnerships are core to Lenovo's strategy.\n",
      "[00:32:52 - 00:32:59] Our long-term partnership with AMD, as you know, Lisa, spans over 25 years and is a testament\n",
      "[00:32:59 - 00:33:00] to this.\n",
      "[00:33:00 - 00:33:07] Together, I think we have driven incredible innovations across PCs, mobile gaming, servers,\n",
      "[00:33:07 - 00:33:10] tablets, edge computing.\n",
      "[00:33:10 - 00:33:17] And for example, our ThinkStation P620 was the first Threadripper Pro workstation to\n",
      "[00:33:17 - 00:33:26] deliver unprecedented performance and flexibility to power AI renderings and workflows.\n",
      "[00:33:26 - 00:33:32] Beyond hardware, the Lenovo AI Engine Plus software uses machine learning in our Legion\n",
      "[00:33:32 - 00:33:40] gaming laptops, integrates with AMD Ryzen processors to dynamically adjust settings\n",
      "[00:33:40 - 00:33:46] and tailor for epic gaming experiences at the highest performance.\n",
      "[00:33:46 - 00:33:54] Our AMD-powered devices, ThinkPad, ThinkBoot, Yoga, Legion, are all well-equipped to handle\n",
      "[00:33:54 - 00:34:01] AI applications, accelerate video editing, enhance 3D rendering, and elevate gaming to\n",
      "[00:34:01 - 00:34:02] new heights.\n",
      "[00:34:02 - 00:34:09] So Lisa, we are very excited for all the innovation that AMD is introducing.\n",
      "[00:34:09 - 00:34:15] And Lenovo definitely will be a great partner to deliver them to the global markets.\n",
      "[00:34:15 - 00:34:22] We can do this because of our global scale, top-notch engineering and design, and then\n",
      "[00:34:22 - 00:34:26] the operational excellence as the world number one PC maker, Lisa.\n",
      "[00:34:26 - 00:34:28] Thank you so much, Luca.\n",
      "[00:34:28 - 00:34:32] And Luca, when we think about all the work we're doing together, today we're talking\n",
      "[00:34:32 - 00:34:37] about third-gen Ryzen AI devices, and I know your team has done a lot, our teams have done\n",
      "[00:34:37 - 00:34:38] a lot together.\n",
      "[00:34:38 - 00:34:42] Can you talk a little bit about your lineup and some of the AI experiences that you have?\n",
      "[00:34:42 - 00:34:43] Yeah, with pleasure.\n",
      "[00:34:43 - 00:34:49] So later this year, we are going to launch Lenovo AI laptops with the third-gen Ryzen\n",
      "[00:34:49 - 00:34:57] AI processors for consumers through our Yoga franchisee, for commercial with our legendary\n",
      "[00:34:57 - 00:35:03] ThinkPad brand, and for small and medium businesses through our ThinkBook lineup.\n",
      "[00:35:03 - 00:35:09] And no matter if you are a creator, an enterprise professional, or a startup entrepreneur, Lenovo\n",
      "[00:35:09 - 00:35:17] will have the perfect Copilot+ laptop with third-gen Ryzen AI, and congratulations\n",
      "[00:35:17 - 00:35:22] operating at the industry-leading over 50 TOPS.\n",
      "[00:35:22 - 00:35:24] Congratulations for that, Lisa.\n",
      "[00:35:24 - 00:35:31] So we'll have also some exclusive Lenovo AI experiences coming to the market this year.\n",
      "[00:35:31 - 00:35:33] One is Creator Zone.\n",
      "[00:35:33 - 00:35:40] We have co-engineered this with AMD on fine tuning the AI model, and this is an exclusive\n",
      "[00:35:40 - 00:35:48] Lenovo software tailor-made for creators, providing tools and features to boost creativity\n",
      "[00:35:48 - 00:35:50] and productivity.\n",
      "[00:35:50 - 00:35:54] And maybe let's take a look at how this software works.\n",
      "[00:35:54 - 00:35:59] So first, let me introduce Lenovo AI Now.\n",
      "[00:35:59 - 00:36:05] That's our native language agent that runs locally on the device.\n",
      "[00:36:05 - 00:36:11] And one of the things that makes this so special is its personal knowledge base.\n",
      "[00:36:11 - 00:36:17] With the right permissions, Lenovo AI Now can interpret user data to provide faster\n",
      "[00:36:17 - 00:36:20] and personalized output.\n",
      "[00:36:20 - 00:36:27] You have seen now AI Now going through a script and generating both a thumbnail and a description\n",
      "[00:36:27 - 00:36:31] to post on YouTube and share with the world.\n",
      "[00:36:31 - 00:36:33] So see, it was very easy, right?\n",
      "[00:36:33 - 00:36:34] Absolutely.\n",
      "[00:36:34 - 00:36:40] Now, let's say the user wants to create images of a fish to post on social media.\n",
      "[00:36:40 - 00:36:44] All they have to do is to use Lenovo Creator Zone.\n",
      "[00:36:44 - 00:36:46] That's our other IP.\n",
      "[00:36:46 - 00:36:52] With text-to-image, Creator Zone can generate an image based off any idea.\n",
      "[00:36:52 - 00:36:59] And if the image needs further refining, the sketch-to-image function can assist the user.\n",
      "[00:36:59 - 00:37:05] And then all of this, all of these images were created with the same prompt and locally\n",
      "[00:37:05 - 00:37:10] on the device with a built-in responsible AI check feature.\n",
      "[00:37:10 - 00:37:11] Fantastic.\n",
      "[00:37:12 - 00:37:18] So we have invested significantly in R&D, as you know, Lisa, and we built a unique Lenovo\n",
      "[00:37:18 - 00:37:29] IPs running on device AI workload, including LLM compression, performance improvement algorithms.\n",
      "[00:37:29 - 00:37:34] And we know, we are confident, that our third-gen Ryzen AI offering will stand out from the\n",
      "[00:37:34 - 00:37:36] competition.\n",
      "[00:37:36 - 00:37:39] And last, but not least, and then I'm over.\n",
      "[00:37:39 - 00:37:47] We also have created Smart Connect, another Lenovo IP that unifies AI PCs, tablets, smartphones,\n",
      "[00:37:47 - 00:37:50] and other IoT into the same Lenovo ecosystem.\n",
      "[00:37:50 - 00:37:51] That's fantastic.\n",
      "[00:37:51 - 00:37:54] Just, it's wonderful to see all of these pieces come together.\n",
      "[00:37:54 - 00:37:58] Now, Luca, you've been holding something, and I think you're going to show us what it is.\n",
      "[00:37:59 - 00:38:00] Is that right?\n",
      "[00:38:00 - 00:38:07] Well, I wasn't supposed to even show this yet, since this is something we will not announce\n",
      "[00:38:07 - 00:38:09] until later this year.\n",
      "[00:38:09 - 00:38:11] But Lisa, you're right.\n",
      "[00:38:11 - 00:38:13] I felt it's just too exciting.\n",
      "[00:38:13 - 00:38:14] You look very happy.\n",
      "[00:38:14 - 00:38:15] I'm very happy.\n",
      "[00:38:15 - 00:38:23] So straight from our R&D, straight from our R&D lab, this is the first-ever sneak peek\n",
      "[00:38:23 - 00:38:30] at our new yoga laptop powered by third-gen Ryzen AI.\n",
      "[00:38:30 - 00:38:31] That's beautiful.\n",
      "[00:38:31 - 00:38:37] Maybe we want to do left.\n",
      "[00:38:37 - 00:38:51] Yeah, so I can't share more for today, but I can tell you this device represents a significant\n",
      "[00:38:51 - 00:38:57] leap forward in next-generation AI computing, will include some of the Lenovo exclusive\n",
      "[00:38:57 - 00:39:02] IP AI features that I mentioned, and this is just the beginning.\n",
      "[00:39:02 - 00:39:09] We cannot wait together to share more and bring these transformative AI PCs to the world\n",
      "[00:39:09 - 00:39:10] very soon.\n",
      "[00:39:10 - 00:39:13] Lisa, thank you for having me, and thanks to everyone.\n",
      "[00:39:13 - 00:39:14] Thank you so much, Luca.\n",
      "[00:39:14 - 00:39:15] Thank you.\n",
      "[00:39:15 - 00:39:16] Thank you so much.\n",
      "[00:39:16 - 00:39:17] Thank you.\n",
      "[00:39:17 - 00:39:20] Thank you.\n",
      "[00:39:20 - 00:39:23] You can see we get very excited about our products.\n",
      "[00:39:23 - 00:39:28] Next, I'd like to welcome one of the most important visionaries and innovators in the\n",
      "[00:39:28 - 00:39:35] Taiwan ecosystem and a very, very close partner, Jonney Shih, chairman of ASUS.\n",
      "[00:39:35 - 00:39:38] Hi, Lisa.\n",
      "[00:39:38 - 00:39:42] Jonney, thank you.\n",
      "[00:39:42 - 00:39:44] Thank you so much for being here.\n",
      "[00:39:44 - 00:39:45] Thank you, Lisa.\n",
      "[00:39:45 - 00:39:50] Yeah, I think it's really my great honor to join you on stage, especially since you are\n",
      "[00:39:50 - 00:39:55] now a legend of the computing industry and the pride of Taiwan.\n",
      "[00:39:55 - 00:39:56] Thank you.\n",
      "[00:39:56 - 00:39:57] Thank you.\n",
      "[00:39:57 - 00:39:58] Thank you.\n",
      "[00:39:58 - 00:39:59] Thank you.\n",
      "[00:39:59 - 00:40:02] Jonney, you are actually a true visionary.\n",
      "[00:40:02 - 00:40:05] I think we all have so much respect for you.\n",
      "[00:40:05 - 00:40:07] You've shaped this industry for so many years.\n",
      "[00:40:07 - 00:40:12] Can you just tell me a little bit about how the landscape of computing is changing and\n",
      "[00:40:12 - 00:40:14] how do you see AI?\n",
      "[00:40:14 - 00:40:23] Yes, Lisa, AI PC will be one of the most disruptive innovations of our lifetime.\n",
      "[00:40:23 - 00:40:31] The ubiquitous AI era is the mega paradigm shift that we have long envisioned at ASUS,\n",
      "[00:40:31 - 00:40:36] and I'm so overjoyed that it's finally becoming a reality.\n",
      "[00:40:36 - 00:40:44] The world will be full of AI brains that come in different forms and sizes, including super,\n",
      "[00:40:44 - 00:40:55] the 1.8 trillion parameters with MOE, big, medium, small, and even tiny, like less than\n",
      "[00:40:55 - 00:40:57] one billion parameters.\n",
      "[00:40:57 - 00:41:07] From the cloud to the edge, to PCs and devices like phones and robots, AI PC will play an\n",
      "[00:41:07 - 00:41:15] extremely critical role in this new distributed hybrid AI ecosystem.\n",
      "[00:41:15 - 00:41:21] Imagine an AI PC with small language model types of AI brains, capable of acting as a\n",
      "[00:41:21 - 00:41:27] personal agent who can understand and help you with your personal needs, preferences,\n",
      "[00:41:27 - 00:41:34] and even work while complementing the super brain in the cloud with local advantage of\n",
      "[00:41:34 - 00:41:42] local latency, high security, and personalization, all the while uploading the cloud computing\n",
      "[00:41:42 - 00:41:45] needs especially for inferencing.\n",
      "[00:41:45 - 00:41:52] Isn't it incredible?\n",
      "[00:41:52 - 00:41:57] This will benefit user productivity like video editing, design work, and scientific computing\n",
      "[00:41:57 - 00:42:00] and a lot more.\n",
      "[00:42:00 - 00:42:06] This vision is amplified and possible because of our partnership with AMD and the launch\n",
      "[00:42:06 - 00:42:09] of the 3rd Gen Ryzen AI.\n",
      "[00:42:09 - 00:42:14] We are definitely co-innovating at the forefront of AI PC together.\n",
      "[00:42:14 - 00:42:19] It is so inspiring, Jonney, to hear you talk with such passion.\n",
      "[00:42:19 - 00:42:22] I think we all can feel your passion going forward.\n",
      "[00:42:22 - 00:42:28] So can you tell us a little bit about your new portfolio of AI PCs with 3rd Gen Ryzen\n",
      "[00:42:28 - 00:42:29] AI?\n",
      "[00:42:30 - 00:42:31] Of course, Lisa.\n",
      "[00:42:31 - 00:42:39] I think later today at 4 p.m. we'll be unveiling a range of cutting-edge AI PCs across our\n",
      "[00:42:39 - 00:42:48] portfolio with brand new ZenBook, ProArt, Vivobook, ASUS TUF, and ROG laptops powered\n",
      "[00:42:48 - 00:42:52] by the 3rd Gen AMD Ryzen AI processors.\n",
      "[00:42:52 - 00:42:59] These new lineups are equipped with the world's most powerful NPU with 50 TOPS and the superior\n",
      "[00:42:59 - 00:43:05] AMD Zen 5 architecture that leads the industry in compute and AI performance.\n",
      "[00:43:05 - 00:43:15] The 3rd Gen Ryzen AI processor is the catalyst to bring in personalized computing to everyone,\n",
      "[00:43:15 - 00:43:21] from content creators to gamers and business professionals, and empowering them like never before.\n",
      "[00:43:23 - 00:43:29] This advancement gives the new ZenBook higher AI performance than MacBook, while making\n",
      "[00:43:29 - 00:43:31] it thinner and lighter as well.\n",
      "[00:43:31 - 00:43:39] ASUS is so proud and honored to be the first OEM partner to make the 3rd Gen Ryzen AI systems\n",
      "[00:43:39 - 00:43:41] available to consumers.\n",
      "[00:43:41 - 00:43:44] It will be ready for purchase in July.\n",
      "[00:43:44 - 00:43:47] Isn't that incredible?\n",
      "[00:43:47 - 00:43:52] Thank you.\n",
      "[00:43:52 - 00:43:58] These are super beautiful systems, Jonney, and, you know, it's also about the experiences,\n",
      "[00:43:58 - 00:44:03] and I know that ASUS has also done a lot to create some new experiences for content creation and creativity.\n",
      "[00:44:03 - 00:44:06] Can you tell us a little bit about that?\n",
      "[00:44:06 - 00:44:08] Sure.\n",
      "[00:44:08 - 00:44:13] We have been working closely with AMD to integrate and optimize the incredible power of Ryzen\n",
      "[00:44:13 - 00:44:19] AI processors on our ASUS Copilot+ PC lineups.\n",
      "[00:44:19 - 00:44:27] This enables us to create exclusive and unprecedented AI apps to empower users to be more efficient\n",
      "[00:44:27 - 00:44:30] and creative than ever before.\n",
      "[00:44:30 - 00:44:36] A great example is one of our recently launched AI apps called StoryCube.\n",
      "[00:44:36 - 00:44:44] Even creators who use multiple devices will love it.\n",
      "[00:44:44 - 00:44:51] StoryCube is an AI-powered digital asset management app designed to provide you with a seamless\n",
      "[00:44:51 - 00:44:54] and efficient file organizing experience.\n",
      "[00:44:54 - 00:45:04] It can act as a handy assistant by automatically identifying your loved ones' faces and even\n",
      "[00:45:04 - 00:45:14] detecting and sorting your media into various scenes, such as scenic road trips, skiing\n",
      "[00:45:14 - 00:45:18] adventures, or adorably puppy moments.\n",
      "[00:45:18 - 00:45:26] With a 50 TOPS capability of the Ryzen AI NPU, StoryCube can drastically shorten\n",
      "[00:45:27 - 00:45:35] AI categorization time from the tens of seconds running only on a CPU to just the blink of an eye.\n",
      "[00:45:36 - 00:45:37] Thank you.\n",
      "[00:45:37 - 00:45:43] You know, Jonney, look, it's really exciting what we're doing on AI PCs, but AMD and ASUS\n",
      "[00:45:43 - 00:45:49] have also had a very long history of partnering across motherboards, graphics cards, and embedded\n",
      "[00:45:49 - 00:45:50] systems.\n",
      "[00:45:50 - 00:45:53] And as we go forward, can you comment about some of that going forward?\n",
      "[00:45:53 - 00:45:54] Sure.\n",
      "[00:45:54 - 00:45:59] It has been a great history together, creating incredible products like the original Crosshair motherboard.\n",
      "[00:46:00 - 00:46:06] ASUS was even the first to push Ryzen gaming system, which received an incredible response\n",
      "[00:46:06 - 00:46:07] from users.\n",
      "[00:46:07 - 00:46:14] Last year, ASUS introduced the first ROG Ally handheld device, which also adopted the AMD\n",
      "[00:46:14 - 00:46:16] Z1 Extreme chip.\n",
      "[00:46:16 - 00:46:24] We have solid leadership in the AMD Ryzen 9 segment with 60% market share, and we are\n",
      "[00:46:24 - 00:46:31] excited about expanding our partnership to offer AI solutions for specific industries\n",
      "[00:46:31 - 00:46:39] like healthcare, education, and smart cities with the goal of revolutionizing these sectors\n",
      "[00:46:39 - 00:46:43] with powerful on-device AI applications.\n",
      "[00:46:43 - 00:46:50] That's why we are so excited to work together in the next-gen AI PC space by combining cutting-edge\n",
      "[00:46:50 - 00:46:59] AMD hardware like Ryzen processors and ASUS software expertise rooted in our design thinking\n",
      "[00:46:59 - 00:47:00] philosophy.\n",
      "[00:47:00 - 00:47:06] We are pushing the boundaries of AI PC innovation and delivering truly groundbreaking AI experience\n",
      "[00:47:06 - 00:47:07] to users.\n",
      "[00:47:07 - 00:47:12] Jonney, all I can say is you are an inspiration to us all.\n",
      "[00:47:12 - 00:47:15] Thank you so much for everything that you've done for our industry, and thank you for your\n",
      "[00:47:15 - 00:47:16] partnership with AMD.\n",
      "[00:47:16 - 00:47:17] Thank you, too.\n",
      "[00:47:17 - 00:47:18] We have a great partnership.\n",
      "[00:47:18 - 00:47:19] Thank you very much.\n",
      "[00:47:19 - 00:47:20] Thank you.\n",
      "[00:47:20 - 00:47:21] Thank you.\n",
      "[00:47:24 - 00:47:30] So I hope you got a feel for all of the customer excitement around third-gen Ryzen AI PCs.\n",
      "[00:47:30 - 00:47:35] I'm very happy to say that the first notebooks will be available in July, and we have more than 100\n",
      "[00:47:36 - 00:47:44] consumer and commercial notebook design wins with Acer, ASUS, HP, Lenovo, MSI, and others.\n",
      "[00:47:44 - 00:47:46] So lots of things to come.\n",
      "[00:47:46 - 00:47:51] So now let's transition from PCs to the edge, where our embedded and adaptive solutions\n",
      "[00:47:51 - 00:47:55] are bringing AI to a diverse set of markets and devices.\n",
      "[00:47:55 - 00:47:59] AMD AI platforms are already broadly deployed at the edge.\n",
      "[00:47:59 - 00:48:06] In healthcare, AMD chips are improving patient outcomes by enhancing medical imaging analysis,\n",
      "[00:48:06 - 00:48:10] accelerating research, and assisting surgeons with precision robotics.\n",
      "[00:48:10 - 00:48:15] In automotive, AMD AI solutions are powering the most advanced safety systems.\n",
      "[00:48:15 - 00:48:21] And in industrial, customers are using AMD technology for AI-assisted robotics and machine\n",
      "[00:48:21 - 00:48:23] vision applications.\n",
      "[00:48:23 - 00:48:27] We are number one in adaptive computing today, and thousands of companies have adopted our\n",
      "[00:48:27 - 00:48:33] XDNA AI adaptive and embedded technologies to power their products and services.\n",
      "[00:48:33 - 00:48:35] Let me just give you a few examples.\n",
      "[00:48:35 - 00:48:43] So Illumina is a global leader in genomics, and they use EPYC and AMD adaptive SoCs with\n",
      "[00:48:43 - 00:48:49] their Splice AI software to identify previously undetectable mutations in patients with rare\n",
      "[00:48:49 - 00:48:51] genetic diseases.\n",
      "[00:48:51 - 00:48:58] In automotive, Subaru is industry's leading eyesight ADAS system, uses Versal to analyze\n",
      "[00:48:58 - 00:49:03] every frame captured by the front camera, and that allows them to identify and alert\n",
      "[00:49:03 - 00:49:06] the driver of possible safety hazards.\n",
      "[00:49:06 - 00:49:12] Hitachi Energy uses AMD adaptive computing products in their widely deployed high-voltage\n",
      "[00:49:12 - 00:49:17] direct current solutions to detect potential electrical issues before they become large\n",
      "[00:49:17 - 00:49:21] problems and cause power outages.\n",
      "[00:49:21 - 00:49:26] And Canon has adopted Versal to power the AI-based free viewpoint video system that\n",
      "[00:49:26 - 00:49:33] captures high-resolution video from over 100 cameras simultaneously, and that allows viewers\n",
      "[00:49:33 - 00:49:37] to experience live events from every angle.\n",
      "[00:49:37 - 00:49:40] Now AI at the Edge is actually a hard problem.\n",
      "[00:49:40 - 00:49:46] It requires the ability to do pre-processing, inferencing, and post-processing all within\n",
      "[00:49:46 - 00:49:47] the device.\n",
      "[00:49:47 - 00:49:53] And only AMD has all of these pieces needed to accelerate end-to-end AI at the Edge.\n",
      "[00:49:53 - 00:49:58] So we combine the adaptive computing engines for pre-processing sensor and other data,\n",
      "[00:49:58 - 00:50:03] with AI engines for inferencing, and then high-performance embedded compute cores for\n",
      "[00:50:03 - 00:50:06] post-processing decision-making.\n",
      "[00:50:06 - 00:50:10] Now today, when you do this, this requires three separate chips.\n",
      "[00:50:10 - 00:50:16] And with our new Versal AI Edge Gen 2 series, we bring all of this leadership compute together\n",
      "[00:50:16 - 00:50:22] to create the first adaptive solution that integrates pre-processing, inferencing, and\n",
      "[00:50:22 - 00:50:24] post-processing in a single chip.\n",
      "[00:50:24 - 00:50:29] So today we're announcing early access for our next-gen Versal platform.\n",
      "[00:50:29 - 00:50:34] More than 30 of our strategic partners are already developing Edge AI devices powered\n",
      "[00:50:34 - 00:50:39] by our new single-chip Versal solution, and we are incredibly excited about the opportunity\n",
      "[00:50:39 - 00:50:44] to drive AI at the Edge and see significant opportunities to extend our embedded market\n",
      "[00:50:44 - 00:50:47] leadership with these new technologies.\n",
      "[00:50:53 - 00:50:57] Okay, now let's turn to the data center.\n",
      "[00:50:57 - 00:51:02] We've built the industry's broadest portfolio of high-performance CPU, GPU, and networking\n",
      "[00:51:02 - 00:51:04] products.\n",
      "[00:51:04 - 00:51:09] And when you look at modern data centers today, they actually run many different workloads.\n",
      "[00:51:09 - 00:51:16] They range from traditional IT applications to smaller enterprise LLMs to large-scale\n",
      "[00:51:16 - 00:51:17] AI applications.\n",
      "[00:51:17 - 00:51:22] And you need different compute engines for each of these workloads, and only AMD has\n",
      "[00:51:22 - 00:51:29] the full portfolio of high-performance CPUs and GPUs to address all of these workloads.\n",
      "[00:51:29 - 00:51:33] From our EPYC processors that deliver leadership performance on general-purpose and mixed-inferencing\n",
      "[00:51:33 - 00:51:40] AI workloads to our industry-leading Instinct GPUs that are built for accelerating AI applications\n",
      "[00:51:40 - 00:51:41] at scale.\n",
      "[00:51:41 - 00:51:48] Today, I'm going to share details of our next-generation data center CPU and GPU offerings.\n",
      "[00:51:48 - 00:51:51] So let's start first with CPUs.\n",
      "[00:51:51 - 00:51:55] If you take a look at the CPU market, EPYC is actually the processor of choice for cloud\n",
      "[00:51:55 - 00:52:01] computing, powering internal workloads for all of the largest hyperscalers and more than\n",
      "[00:52:01 - 00:52:05] 900 public instances from all the major cloud providers.\n",
      "[00:52:05 - 00:52:11] Every day, billions of people around the world use cloud services powered by EPYC.\n",
      "[00:52:11 - 00:52:19] That includes Facebook, Instagram, LinkedIn, Microsoft Teams, Zoom, Netflix, WeChat, WhatsApp,\n",
      "[00:52:19 - 00:52:21] and many, many more.\n",
      "[00:52:21 - 00:52:23] All of that is on EPYC.\n",
      "[00:52:23 - 00:52:30] Now we launched EPYC in 2017, and with every generation, more and more customers have adopted\n",
      "[00:52:30 - 00:52:36] EPYC because of our leading performance, our leading energy efficiency, and our leading\n",
      "[00:52:36 - 00:52:38] total cost of ownership.\n",
      "[00:52:38 - 00:52:45] And I'm very proud to say that we're at 33% share now and growing.\n",
      "[00:52:49 - 00:52:54] Now, when you look at today's data centers, most data centers are actually powered by\n",
      "[00:52:54 - 00:52:57] processors that are more than five years old.\n",
      "[00:52:57 - 00:53:03] And when you look at the virtualization performance of our latest generation server CPUs, the\n",
      "[00:53:03 - 00:53:09] new technology is so much better that EPYC delivers five times more performance compared\n",
      "[00:53:09 - 00:53:12] to those legacy processors.\n",
      "[00:53:12 - 00:53:17] And even comparing to the best processors today from the competition, our performance\n",
      "[00:53:17 - 00:53:20] is one and a half times faster.\n",
      "[00:53:20 - 00:53:24] Many enterprises today are actually looking to modernize their general purpose computing\n",
      "[00:53:24 - 00:53:29] infrastructure and add new AI capabilities, often within the same footprint.\n",
      "[00:53:29 - 00:53:35] And by refreshing their data centers with 4th Gen EPYC, you can really accomplish this.\n",
      "[00:53:35 - 00:53:41] You can actually replace five legacy servers with a single server that reduces rack space\n",
      "[00:53:41 - 00:53:46] by 80% and consumes 65% less energy.\n",
      "[00:53:46 - 00:53:52] Now many enterprise customers are also wanting to run a combination of general purpose and\n",
      "[00:53:52 - 00:53:55] AI workloads without adding GPUs.\n",
      "[00:53:55 - 00:53:58] And EPYC is, again, the best option for that.\n",
      "[00:53:58 - 00:54:05] Looking at EPYC, we are 1.7 times faster when running the industry standard TPX AI benchmark\n",
      "[00:54:05 - 00:54:10] that measures end-to-end AI pipeline across different use cases and algorithms.\n",
      "[00:54:10 - 00:54:16] 4th Gen EPYC is clearly the industry's best server CPU, but we're always pushing the envelope\n",
      "[00:54:16 - 00:54:18] to deliver more performance.\n",
      "[00:54:18 - 00:54:20] So I have something to show you today.\n",
      "[00:54:20 - 00:54:32] It's actually the preview of our upcoming 5th Gen EPYC processor codenamed Turin.\n",
      "[00:54:32 - 00:54:37] So please take a look at Turin for the very first time.\n",
      "[00:54:37 - 00:54:47] Turin features 192 cores and 384 threads and has 13 different chiplets built in 3 and 6\n",
      "[00:54:47 - 00:54:50] nanometer process technology.\n",
      "[00:54:50 - 00:54:53] There's a lot of technology on Turin.\n",
      "[00:54:53 - 00:54:58] It supports all the latest memory and IO standards and is a drop-in replacement for\n",
      "[00:54:58 - 00:55:00] existing 4th Gen EPYC platforms.\n",
      "[00:55:03 - 00:55:04] Thank you, Drew.\n",
      "[00:55:07 - 00:55:12] Turin will extend EPYC's leadership in general purpose and high performance computing workloads.\n",
      "[00:55:12 - 00:55:15] So let's take a look at some of that performance.\n",
      "[00:55:15 - 00:55:20] NAMD is a very compute-intensive scientific software that simulates complex molecular\n",
      "[00:55:20 - 00:55:22] systems and structures.\n",
      "[00:55:22 - 00:55:29] When simulating a 20 million atom model, a 128 core version of Turin is more than 3 times\n",
      "[00:55:29 - 00:55:35] faster than the competition's best, enabling researchers to more quickly complete models\n",
      "[00:55:35 - 00:55:41] that can lead to breakthroughs in drug research, material science, and other fields.\n",
      "[00:55:41 - 00:55:46] Now Turin also excels at AI inferencing performance when running smaller large language models.\n",
      "[00:55:46 - 00:55:48] So I want to show you a demo here.\n",
      "[00:55:48 - 00:55:53] Now what this demo compares is the performance of Turin when running a typical enterprise\n",
      "[00:55:53 - 00:55:59] deployment of Llama 2 virtual assistants with a minimum guarantee latency to ensure a high\n",
      "[00:55:59 - 00:56:01] quality user experience.\n",
      "[00:56:01 - 00:56:07] Both servers begin by loading multiple Llama 2 instances with each assistant being asked\n",
      "[00:56:07 - 00:56:10] to summarize an uploaded document.\n",
      "[00:56:10 - 00:56:14] Right away, you can see that the Turin server on the right is adding double the number of\n",
      "[00:56:14 - 00:56:19] sessions in the same amount of time while responding to user requests significantly\n",
      "[00:56:19 - 00:56:22] faster than the competition.\n",
      "[00:56:22 - 00:56:27] And while the other server reaches a maximum number of sessions, you'll see it stop soon,\n",
      "[00:56:27 - 00:56:32] it basically can't support the latency requirements anymore.\n",
      "[00:56:32 - 00:56:36] Turin continues scaling and delivers a sustained throughput of nearly four times more tokens\n",
      "[00:56:36 - 00:56:37] per second.\n",
      "[00:56:43 - 00:56:48] That means when you use Turin, you need less hardware to do the same work.\n",
      "[00:56:48 - 00:56:53] And in addition to leadership summarization performance, Turin also delivers leadership\n",
      "[00:56:53 - 00:56:59] performance across a number of other different enterprise AI use cases, including two and\n",
      "[00:56:59 - 00:57:04] a half times more performance when translating large documents, and more than five times\n",
      "[00:57:04 - 00:57:08] better performance when running a support chatbot.\n",
      "[00:57:08 - 00:57:12] Our customers are super excited about Turin, and I know many of our partners are actually\n",
      "[00:57:12 - 00:57:14] here in the audience today.\n",
      "[00:57:14 - 00:57:17] And I want to say we're on track to launch in the second half of this year.\n",
      "[00:57:23 - 00:57:31] So now let's turn to data center GPUs and some big updates on our Instinct accelerators.\n",
      "[00:57:31 - 00:57:36] We launched MI300 last December, and it's quickly become the fastest ramping product\n",
      "[00:57:36 - 00:57:38] in AMD history.\n",
      "[00:57:38 - 00:57:42] Microsoft, Meta, and Oracle have all adopted MI300.\n",
      "[00:57:42 - 00:57:48] Every major server OEM is offering MI300 platforms, and we have built deep partnerships\n",
      "[00:57:48 - 00:57:54] with a broad ecosystem of CSP and ODM partners, again, many, many thanks to our ODM partners\n",
      "[00:57:54 - 00:57:58] who are here today, that are offering Instinct solutions.\n",
      "[00:57:58 - 00:58:03] Now if you look at today's enterprise generative AI workloads, MI300X provides out-of-the-box\n",
      "[00:58:03 - 00:58:10] support for all of the most common models, including GPT, Llama, Mistral, PHY, and many\n",
      "[00:58:10 - 00:58:11] more.\n",
      "[00:58:11 - 00:58:16] We've made so much progress in the last year on our ROCm software stack, working very\n",
      "[00:58:16 - 00:58:21] closely with the open source community at every layer of the stack, while adding new\n",
      "[00:58:21 - 00:58:26] features and functionality that make it incredibly easy for customers to deploy AMD Instinct\n",
      "[00:58:26 - 00:58:29] in their software environment.\n",
      "[00:58:29 - 00:58:34] Over the last six months, we've added support for more AMD AI hardware and operating systems.\n",
      "[00:58:34 - 00:58:39] We've integrated open source libraries like VLLM and frameworks like JAX.\n",
      "[00:58:39 - 00:58:43] We've enabled support for state-of-the-art attention algorithms.\n",
      "[00:58:43 - 00:58:47] We've improved computation and communication libraries, all of which have contributed to\n",
      "[00:58:47 - 00:58:52] significant increases in the gen AI performance for MI300.\n",
      "[00:58:52 - 00:58:58] Now with all of these latest ROCm updates, MI300X delivers significantly better inferencing\n",
      "[00:58:58 - 00:59:03] performance compared to the competition on some of the industry's most demanding and\n",
      "[00:59:03 - 00:59:05] popular models.\n",
      "[00:59:05 - 00:59:11] That is, we are 1.3 times more performance on Meta's latest Llama 3 70B model compared\n",
      "[00:59:11 - 00:59:19] to H100, and we're 1.2 times more performance on Mistral's 7B model.\n",
      "[00:59:19 - 00:59:22] We've also expanded our work with the open source AI community.\n",
      "[00:59:22 - 00:59:28] More than 700,000 hugging face models now run out of the box using ROCm on MI300X.\n",
      "[00:59:28 - 00:59:34] This is a direct result of all of our investments in development and test environments that\n",
      "[00:59:34 - 00:59:37] ensure a broad range of models work on Instinct.\n",
      "[00:59:37 - 00:59:43] The industry is also making significant progress at raising the level of abstraction at which\n",
      "[00:59:43 - 00:59:45] developers code to GPUs.\n",
      "[00:59:45 - 00:59:50] We want to do this because people want choice in the industry, and we're really happy to\n",
      "[00:59:50 - 00:59:55] say that we've made significant progress with our partners to enable this.\n",
      "[00:59:55 - 01:00:01] For example, our close collaboration with OpenAI is ensuring full support of MI300X\n",
      "[01:00:01 - 01:00:08] with Triton, providing a vendor agnostic option to rapidly develop highly performant LLM kernels.\n",
      "[01:00:08 - 01:00:13] And we've also continued to make excellent progress adding support for AMD AI hardware\n",
      "[01:00:13 - 01:00:18] into the leading frameworks like PyTorch, TensorFlow, and JAX.\n",
      "[01:00:18 - 01:00:23] Now we're also working very closely with the leading AI developers to optimize their models\n",
      "[01:00:23 - 01:00:30] for MI300, so I'm very excited to welcome Christian Laforte, CTO and co-CEO of Stability AI,\n",
      "[01:00:30 - 01:00:36] an important AMD partner known for delivering the Breakthrough Stable Diffusion Open Access\n",
      "[01:00:36 - 01:00:38] AI models.\n",
      "[01:00:40 - 01:00:43] Hello, Christian, how are you?\n",
      "[01:00:43 - 01:00:44] Thank you.\n",
      "[01:00:44 - 01:00:45] I'm great.\n",
      "[01:00:45 - 01:00:47] It's a great honor to be here to represent my colleagues and everyone else who makes\n",
      "[01:00:47 - 01:00:50] Stability AI a really interesting player in the ecosystem.\n",
      "[01:00:50 - 01:00:54] Well, you know, we've showed a lot of Stability AI today.\n",
      "[01:00:54 - 01:00:59] You're known for delivering these Breakthrough Open Access AI models that generate, you know,\n",
      "[01:00:59 - 01:01:02] images, video, language, code, all of these things.\n",
      "[01:01:02 - 01:01:06] Can you share some insights into how these models are pushing the boundaries of what's\n",
      "[01:01:06 - 01:01:07] possible?\n",
      "[01:01:07 - 01:01:12] Yes, we're seeing incredible gains in productivity in every industry, and many were made possible\n",
      "[01:01:12 - 01:01:17] because we did a crazy thing and we released our models and our source code for free.\n",
      "[01:01:17 - 01:01:21] And so this allowed millions of developers and enthusiasts and thousands of researchers\n",
      "[01:01:21 - 01:01:27] to adapt their models to make new discoveries at record pace and to create new applications\n",
      "[01:01:27 - 01:01:28] extremely fast.\n",
      "[01:01:28 - 01:01:33] Take for instance touching up old family photos to improve their resolution or quality or\n",
      "[01:01:33 - 01:01:38] maybe to remove someone you never, ever want to see again in your whole life.\n",
      "[01:01:38 - 01:01:42] Doing this, well, used to take years of experience and sometimes hours of tedious work for\n",
      "[01:01:42 - 01:01:44] each image.\n",
      "[01:01:44 - 01:01:48] Now applications like Stable Assistant and Stable Artisan and a lot of other applications\n",
      "[01:01:48 - 01:01:54] that leverage stable diffusion can allow anyone to create and edit images in seconds.\n",
      "[01:01:54 - 01:02:00] And we're seeing similar gains in productivity not just in images but in other research areas\n",
      "[01:02:00 - 01:02:04] that we're involved in, in language, coding, music, speech, and 3D.\n",
      "[01:02:04 - 01:02:09] And combining all of those together, we aim to soon boost by at least 10x the productivity\n",
      "[01:02:09 - 01:02:12] of filmmaking and video game creation.\n",
      "[01:02:12 - 01:02:14] That's fantastic, Christian.\n",
      "[01:02:14 - 01:02:18] Now I understand you have some big news to tell the audience today.\n",
      "[01:02:18 - 01:02:19] Yes.\n",
      "[01:02:19 - 01:02:23] So basically the wait for Stable Diffusion 3 is almost over.\n",
      "[01:02:23 - 01:02:27] We appreciate the community's patience and understanding as we dedicated extra effort\n",
      "[01:02:27 - 01:02:29] to improve its quality and safety.\n",
      "[01:02:29 - 01:02:34] Today we're announcing that on June 12th we will release the Stable Diffusion 3 medium\n",
      "[01:02:34 - 01:02:36] model for everyone to download.\n",
      "[01:02:41 - 01:02:44] A lot of work went into this.\n",
      "[01:02:44 - 01:02:49] And we're really excited to see what the community will end up doing with this.\n",
      "[01:02:49 - 01:02:54] One thing that is maybe not obvious to non-technical people is that like it used to be that the\n",
      "[01:02:54 - 01:03:00] frontier of research led to basically these models like stable diffusion.\n",
      "[01:03:00 - 01:03:05] But nowadays what's happening is that there's like a new, it's like a natural evolution\n",
      "[01:03:05 - 01:03:06] basically.\n",
      "[01:03:06 - 01:03:10] Like these models are getting combined together in all kinds of novel ways and by releasing\n",
      "[01:03:10 - 01:03:16] them openly we basically allow millions of people to help discover the best way to bring\n",
      "[01:03:16 - 01:03:19] those together and unlock new use cases.\n",
      "[01:03:19 - 01:03:26] So this SD3 medium, it's an optimized version of SD3 that achieves unprecedented visual\n",
      "[01:03:26 - 01:03:30] quality and that the community will be able to improve for their own specific needs to\n",
      "[01:03:30 - 01:03:35] help us discover the next frontier of generative AI.\n",
      "[01:03:35 - 01:03:39] It will of course run super fast on the MI300.\n",
      "[01:03:39 - 01:03:46] And it's also compact enough to run on the Ryzen AI laptops that you've just announced.\n",
      "[01:03:46 - 01:03:49] So here's an image produced with Stable Diffusion 3.\n",
      "[01:03:49 - 01:03:55] We challenged it to basically illustrate the famous Taiwan night markets, what it looks like. \n",
      "[01:03:56 - 01:03:57] That looks very nice Christian.\n",
      "[01:03:57 - 01:03:58] Thank you.\n",
      "[01:03:58 - 01:03:59] It looks very nice.\n",
      "[01:03:59 - 01:04:06] So if you look really, really closely you'll notice like it's not quite photorealistic,\n",
      "[01:04:06 - 01:04:11] but I think it captured really well like the different elements of the text prompt.\n",
      "[01:04:11 - 01:04:15] And it's especially impressive when you think that it was generated so much faster than\n",
      "[01:04:15 - 01:04:18] actually typing this long text prompt.\n",
      "[01:04:18 - 01:04:24] So it captured the pedestrians that are walking, the street that is made of stones, the fact\n",
      "[01:04:24 - 01:04:27] that it is during the night, there's the trees and so on.\n",
      "[01:04:27 - 01:04:33] So basically like SD3 is able to do this using a bunch of new innovations including\n",
      "[01:04:33 - 01:04:39] the multimodal diffusion transformer architecture that allow it to understand visual concepts\n",
      "[01:04:39 - 01:04:42] and text prompts far better than previous models.\n",
      "[01:04:42 - 01:04:47] It supports both simple prompts, so you don't need to become an expert at these, but you\n",
      "[01:04:47 - 01:04:53] can also use much more complex ones and it will try to bring together all of the different\n",
      "[01:04:53 - 01:04:55] elements of it.\n",
      "[01:04:55 - 01:05:00] And SD3 excels at all kinds of artistic styles and photorealism.\n",
      "[01:05:00 - 01:05:05] So here's an example that is actually a really challenging example and we're comparing it\n",
      "[01:05:05 - 01:05:12] with our previous version model, stable diffusion excel that we released less than a year ago.\n",
      "[01:05:12 - 01:05:17] And it's especially challenging because it involves hands that are notoriously hard for\n",
      "[01:05:17 - 01:05:19] these models to replicate.\n",
      "[01:05:19 - 01:05:24] It involves these repeating patterns like the strings and the guitar and the frets.\n",
      "[01:05:24 - 01:05:29] These are all really challenging for these models to understand and draw accurately.\n",
      "[01:05:29 - 01:05:34] So notice how SD3 generated more realistic details like the shape of the guitar and the\n",
      "[01:05:34 - 01:05:35] hands.\n",
      "[01:05:35 - 01:05:39] And if you look really, really closely, you may notice that there are a few imperfections\n",
      "[01:05:39 - 01:05:40] here and there.\n",
      "[01:05:40 - 01:05:45] So it's still not quite perfect, but it's a big improvement over the previous generation.\n",
      "[01:05:45 - 01:05:52] It's fantastic, Christian, and I know that your team's been working a lot on SD3.\n",
      "[01:05:52 - 01:05:55] What's your experience been like with MI300?\n",
      "[01:05:55 - 01:05:56] It's wonderful.\n",
      "[01:05:56 - 01:06:01] 192 gigabytes of HBM, that's really a game changer.\n",
      "[01:06:01 - 01:06:07] It's like having more memory basically is often like, it's the way that we can unlock\n",
      "[01:06:07 - 01:06:12] new models and it's often like the number one factor that will help us to train bigger\n",
      "[01:06:12 - 01:06:15] models faster and more efficiently.\n",
      "[01:06:15 - 01:06:20] And I'll give an example that we've actually just encountered in collaborating with AMD.\n",
      "[01:06:20 - 01:06:26] So we have this creative upscaler feature in our API, and basically the way it works\n",
      "[01:06:26 - 01:06:32] is that it can take an old photo and an old image that is less than one megapixel and\n",
      "[01:06:32 - 01:06:37] really blow out the resolution and improve the quality at the same time.\n",
      "[01:06:37 - 01:06:45] And so this creative upscaler, like we were happy when we were able to reach 30 megapixels\n",
      "[01:06:45 - 01:06:53] on the H100, but once we basically ported our code over to the MI300, which by the way\n",
      "[01:06:53 - 01:06:58] was pretty much no effort, we were able to reach 100 megapixels.\n",
      "[01:06:58 - 01:07:04] And you know content creators, they always want more pixels, so this makes a huge difference.\n",
      "[01:07:04 - 01:07:11] And the fact that we didn't have to really make any effort to actually achieve this,\n",
      "[01:07:11 - 01:07:12] it's a big step up.\n",
      "[01:07:16 - 01:07:21] So researchers and engineers are really going to love the incredible memory capacity and\n",
      "[01:07:21 - 01:07:26] the bandwidth advantages that the AMD Instinct GPUs deliver out of the box.\n",
      "[01:07:26 - 01:07:31] So Lisa, moving forward, we'd really love to collaborate more closely with AMD because\n",
      "[01:07:31 - 01:07:34] we'd like to create a new state-of-the-art video model.\n",
      "[01:07:34 - 01:07:39] We need a lot more memory, we need a lot more compute to do this, and so we'd love to collaborate\n",
      "[01:07:39 - 01:07:43] more closely with your team to achieve this and to release this for the whole world to\n",
      "[01:07:43 - 01:07:44] enjoy.\n",
      "[01:07:44 - 01:07:45] That sounds fantastic.\n",
      "[01:07:45 - 01:07:46] It sounds like you need some GPUs.\n",
      "[01:07:46 - 01:07:47] Yes.\n",
      "[01:07:47 - 01:07:48] Thank you.\n",
      "[01:07:48 - 01:07:49] Thank you so much.\n",
      "[01:07:49 - 01:07:50] We're at the right place for this.\n",
      "[01:07:50 - 01:07:51] Thank you so much, Christian.\n",
      "[01:07:51 - 01:07:52] Thank you.\n",
      "[01:07:52 - 01:07:53] Have a great Computex.\n",
      "[01:07:56 - 01:08:00] You can see all of the innovation that's happening in such a short amount of time.\n",
      "[01:08:00 - 01:08:06] Now earlier in the show, I was joined by Microsoft's Pavan Davuluri, who shared the great work\n",
      "[01:08:06 - 01:08:10] that we're doing together on Copilot+ PCs.\n",
      "[01:08:10 - 01:08:14] Microsoft is also one of our most strategic data center partners, and we've been working\n",
      "[01:08:14 - 01:08:18] very closely with them on our EPYC and Instinct roadmap.\n",
      "[01:08:18 - 01:08:23] To hear more about our partnership and how Microsoft is using MI300X across your infrastructure,\n",
      "[01:08:23 - 01:08:26] here's Microsoft Chairman and CEO Satya Nadella.\n",
      "[01:08:26 - 01:08:29] Thank you so much, Lisa.\n",
      "[01:08:29 - 01:08:32] Great to be with all of you at Computex.\n",
      "[01:08:32 - 01:08:39] We're in the midst of a massive AI platform shift with the promise to transform how we\n",
      "[01:08:39 - 01:08:40] live and work.\n",
      "[01:08:40 - 01:08:46] We are committed to partnering broadly across the industry to make this vision real.\n",
      "[01:08:46 - 01:08:51] That's why our deep partnership with AMD, which has spanned multiple computing platforms,\n",
      "[01:08:51 - 01:08:57] from the PC to custom silicon for Xbox, and now to AI, is so important to us.\n",
      "[01:08:57 - 01:09:02] As Pavan highlighted, we are excited to partner with you to deliver these new Ryzen AI powered\n",
      "[01:09:02 - 01:09:08] Copilot+ PCs, and we're also thrilled to announce last month that we were the first\n",
      "[01:09:08 - 01:09:15] cloud to deliver general availability of virtual machines using AMD's MI300X accelerator.\n",
      "[01:09:15 - 01:09:21] It's a massive milestone for both our companies, and it gives our customers access to very\n",
      "[01:09:21 - 01:09:25] impressive performance and efficiency for their most demanding AI workloads.\n",
      "[01:09:25 - 01:09:31] In fact, it offers today the leading price performance for GPT workloads.\n",
      "[01:09:31 - 01:09:32] This is just the start.\n",
      "[01:09:32 - 01:09:38] We are very committed to our collaboration with AMD, and we'll continue to push AI progress\n",
      "[01:09:38 - 01:09:43] forward together across the cloud and edge to bring new value to our joint customers.\n",
      "[01:09:43 - 01:09:43] Thank you all so very much.\n",
      "[01:09:50 - 01:09:51] Thank you so much, Satya.\n",
      "[01:09:52 - 01:09:58] We're so proud of our work with Microsoft, and as you heard from Satya, MI300 delivers\n",
      "[01:09:58 - 01:10:04] the best price performance today for GPT-4 workloads, and it's being deployed broadly\n",
      "[01:10:04 - 01:10:07] across Microsoft's AI compute infrastructure.\n",
      "[01:10:07 - 01:10:13] Now let me show you one more example of MI300 being used to power OpenAI's Wanderlust travel\n",
      "[01:10:13 - 01:10:17] assistant built on GPT-4.\n",
      "[01:10:17 - 01:10:22] So again, let's start by letting the tool know that we're interested in Taiwan and that\n",
      "[01:10:22 - 01:10:27] we're going to be attending Computex.\n",
      "[01:10:27 - 01:10:30] And you might ask something about, you know, who's the opening keynote?\n",
      "[01:10:41 - 01:10:45] Got it right.\n",
      "[01:10:45 - 01:10:50] Now let's also ask Wanderlust, what other interesting sites should we see in Taipei?\n",
      "[01:10:50 - 01:10:55] And you can see almost instantly we get lots of options of things to do near the convention center.\n",
      "[01:10:56 - 01:11:00] But if we want to narrow it down to just a few, because we only have a day, we can ask\n",
      "[01:11:00 - 01:11:05] it to plan a day for us, and that day would include things like Elephant Mountain and\n",
      "[01:11:05 - 01:11:08] Taipei 101, and you get the full itinerary.\n",
      "[01:11:15 - 01:11:18] I think it just gives you an example of the power of AI.\n",
      "[01:11:18 - 01:11:24] I mean, Wanderlust on MI300 looks wonderful, but it really shows the power of these assistive agents\n",
      "[01:11:25 - 01:11:31] and how easily it is for developers to seamlessly integrate gen AI models into their applications\n",
      "[01:11:31 - 01:11:35] so that we can make AI extremely helpful for all of us.\n",
      "[01:11:35 - 01:11:40] Now the customer response to MI300 has been overwhelmingly positive, and it's just so\n",
      "[01:11:40 - 01:11:45] clear that the demand for AI is just accelerating so much going forward.\n",
      "[01:11:45 - 01:11:49] We're really just at the beginning of a decade-long mega cycle for AI.\n",
      "[01:11:49 - 01:11:55] And to address this incredible demand, I have a very exciting roadmap to show you.\n",
      "[01:11:55 - 01:12:00] We launched MI300X last year with leadership inference performance, memory size, and compute\n",
      "[01:12:00 - 01:12:06] capabilities, and we have now expanded our roadmap so it's on an annual cadence.\n",
      "[01:12:06 - 01:12:10] That means a new product family every year.\n",
      "[01:12:10 - 01:12:16] Later this year, we plan to launch MI325X with faster and more memory, followed by our\n",
      "[01:12:16 - 01:12:22] MI350 series in 2025 that will use our new CDNA 4 architecture.\n",
      "[01:12:22 - 01:12:29] And both the MI325 and 350 series will leverage the same industry standard universal baseboard\n",
      "[01:12:29 - 01:12:35] OCP server design used by MI300, and what that means is that our customers can very\n",
      "[01:12:35 - 01:12:38] quickly adopt this new technology.\n",
      "[01:12:38 - 01:12:45] And then in 2026, we'll deliver another brand-new architecture with CDNA next in the MI400 series.\n",
      "[01:12:46 - 01:12:50] So let me show you a little bit, starting with MI325.\n",
      "[01:12:50 - 01:12:59] MI325 extends our leadership in generative AI with up to 288 gigabytes of ultra-fast\n",
      "[01:12:59 - 01:13:06] HBM3E memory with 6 terabytes per second of memory bandwidth, and it uses the same infrastructure\n",
      "[01:13:06 - 01:13:11] as MI300, which makes it easy for customers to transition.\n",
      "[01:13:11 - 01:13:13] Now let me show you some competitive data.\n",
      "[01:13:13 - 01:13:20] Prior to the competition, MI325 offers twice the memory, 1.3 times faster memory bandwidth,\n",
      "[01:13:20 - 01:13:24] and 1.3 times more peak compute performance.\n",
      "[01:13:24 - 01:13:28] And based on this larger memory capacity, you heard what Christian said about the importance\n",
      "[01:13:28 - 01:13:30] of memory.\n",
      "[01:13:30 - 01:13:37] A single server with eight MI325 accelerators can run advanced models up to 1 trillion parameters.\n",
      "[01:13:38 - 01:13:45] That's double the size supported by an H200 server.\n",
      "[01:13:49 - 01:13:55] And then moving into 2025, we'll introduce our CDNA 4 architecture, which will deliver\n",
      "[01:13:55 - 01:13:59] the biggest generational leap in AI performance in our history.\n",
      "[01:13:59 - 01:14:05] The MI350 series will be built with advanced 3-nanometer process technology and supports\n",
      "[01:14:06 - 01:14:12] for FP4 and FP6 data types, and will again drop into the same infrastructure as MI300\n",
      "[01:14:12 - 01:14:14] and MI325.\n",
      "[01:14:14 - 01:14:19] We are super excited about the AI performance of CDNA 4.\n",
      "[01:14:19 - 01:14:24] So if you just take a look at that history, when we launched CDNA 3, we were eight times\n",
      "[01:14:24 - 01:14:29] more AI performance compared to our prior generation.\n",
      "[01:14:29 - 01:14:36] And with CDNA 4, we're on track to deliver 35 times increase.\n",
      "[01:14:36 - 01:14:42] That's 35 times increase in performance compared to CDNA 3.\n",
      "[01:14:42 - 01:14:49] And when you compare MI350 series to B200, Instinct supports up to 1.5 times more memory\n",
      "[01:14:50 - 01:14:55] and delivers 1.2 times more performance overall.\n",
      "[01:14:55 - 01:15:02] We are very excited about our multi-year Instinct and ROCm roadmaps, and I can't\n",
      "[01:15:03 - 01:15:08] wait to bring all of this new performance to our AI customers.\n",
      "[01:15:08 - 01:15:12] Now I have one more topic I'd like to talk about today, and it's really, in addition\n",
      "[01:15:12 - 01:15:17] to our focus on Instinct, we've also made significant progress driving the development\n",
      "[01:15:17 - 01:15:20] of high-performance AI networking infrastructure systems.\n",
      "[01:15:21 - 01:15:26] AI network fabrics need to support fast switching rates with very low latency, and they must\n",
      "[01:15:26 - 01:15:30] scale to connect thousands of accelerator nodes.\n",
      "[01:15:30 - 01:15:35] At AMD, we believe that the future of AI networking must be open.\n",
      "[01:15:35 - 01:15:41] Open to allow everyone in the industry to innovate and drive the best solutions together.\n",
      "[01:15:41 - 01:15:46] So for both inferencing and training, it's actually critical to scale up the performance\n",
      "[01:15:46 - 01:15:52] of hundreds of accelerators, connecting the GPUs in a rack or pod with an incredibly fast,\n",
      "[01:15:52 - 01:15:57] highly resilient interconnect, so they can work as a single compute node to run the largest\n",
      "[01:15:57 - 01:16:00] models with the fastest responses.\n",
      "[01:16:00 - 01:16:05] Last week, I'm very happy to say that many of the largest chip, cloud, and systems companies\n",
      "[01:16:05 - 01:16:11] came together to announce plans to develop an open standard for a high-performance fabric\n",
      "[01:16:11 - 01:16:14] that can officially connect hundreds of accelerators.\n",
      "[01:16:14 - 01:16:20] We call this Ultra Accelerator Link, or UA Link, and it's an optimized load store fabric\n",
      "[01:16:20 - 01:16:27] designed to run at high data rates and leverages AMD's proven infinity fabric technology.\n",
      "[01:16:27 - 01:16:32] We actually believe UA Link will be the best solution for scaling accelerators of all types,\n",
      "[01:16:32 - 01:16:39] not just GPUs, but all accelerators, and will be a great alternative to proprietary options.\n",
      "[01:16:39 - 01:16:45] The UA Link 1.0 standard is on track for later this year, with chips supporting UA Link already\n",
      "[01:16:45 - 01:16:48] well into development from multiple vendors.\n",
      "[01:16:48 - 01:16:54] And now the other part of training large models is also the need for scale-out performance,\n",
      "[01:16:54 - 01:16:59] connecting multiple accelerator pods to work together with at-scale installations often\n",
      "[01:16:59 - 01:17:03] spanning hundreds of thousands of GPUs.\n",
      "[01:17:03 - 01:17:08] A broad group of industry leaders formed the Ultra Ethernet Consortium last year to address\n",
      "[01:17:08 - 01:17:15] this challenge, and UAC is the high-performance technology with leading signaling rates.\n",
      "[01:17:15 - 01:17:21] It has extensions such as RoCE for RDMA to efficiently move data between nodes, and it\n",
      "[01:17:21 - 01:17:25] has a new set of innovations developed specifically for AI supercomputers.\n",
      "[01:17:25 - 01:17:30] It's incredibly scalable, it offers the latest switching technology from leading vendors\n",
      "[01:17:30 - 01:17:36] such as Broadcom, Cisco, and Marvell, and above all, it's open.\n",
      "[01:17:36 - 01:17:42] Open means that as an industry we can innovate on top of UEC and solve the needed problems,\n",
      "[01:17:42 - 01:17:46] and the industry can work together to build out the best possible high-performance interconnect\n",
      "[01:17:46 - 01:17:49] for AI and HPC.\n",
      "[01:17:49 - 01:17:51] So when you look ahead, what does this mean?\n",
      "[01:17:51 - 01:17:53] That means we have all the pieces.\n",
      "[01:17:53 - 01:17:58] We have UA Link and Ultra Ethernet, and now we have the complete networking solution for\n",
      "[01:17:58 - 01:18:04] highly performant, highly interoperable, and highly resilient AI data centers that can\n",
      "[01:18:04 - 01:18:08] run the most advanced frontier models.\n",
      "[01:18:08 - 01:18:13] So I hope you can see now that AMD is the only company that can deliver the full set\n",
      "[01:18:13 - 01:18:20] of CPU, GPU, and networking solutions to address all of the needs of the modern data center,\n",
      "[01:18:20 - 01:18:25] and we have accelerated our roadmaps to deliver even more innovation across both our Instinct\n",
      "[01:18:25 - 01:18:31] and EPYC portfolios, while also working with an open ecosystem of other leaders to deliver\n",
      "[01:18:31 - 01:18:33] industry-leading networking solutions.\n",
      "[01:18:33 - 01:18:36] Now, it's been a wonderful morning.\n",
      "[01:18:36 - 01:18:40] We have so much that we talked about, so let me just wrap things up.\n",
      "[01:18:40 - 01:18:45] We showed you a lot of new products today, from our latest Ryzen 9000 desktops and \n",
      "[01:18:45 - 01:18:51] third-gen Ryzen AI notebook processors with leadership, compute, and AI performance, to our single-chip\n",
      "[01:18:51 - 01:18:57] Versal Gen 2 series that will bring more AI capabilities to the edge, to our next-generation Turin\n",
      "[01:18:58 - 01:19:03] processors that extend the leadership and efficiency of our EPYC portfolio, and our\n",
      "[01:19:03 - 01:19:09] expanded set of Instinct accelerators that will deliver an annual cadence of higher performance.\n",
      "[01:19:09 - 01:19:14] And what I can say is this is an incredible time to be in the technology industry.\n",
      "[01:19:14 - 01:19:18] It's an incredible pace of innovation, and I couldn't be more excited about all of the\n",
      "[01:19:18 - 01:19:24] work that we're going to do together in high performance and AI computing as an industry.\n",
      "[01:19:24 - 01:19:30] So a very, very special thank you to all of our partners who joined us today, Microsoft,\n",
      "[01:19:30 - 01:19:35] HP, Asus, Lenovo, and Stability.AI, and especially thank you for all of our partners here in\n",
      "[01:19:35 - 01:19:37] Taiwan and around the world.\n",
      "[01:19:37 - 01:19:42] Thank you for being such a great audience, and have a great Computex 2024.\n",
      "[01:19:42 - 01:19:43] Thank you.\n",
      "Temporary directory created: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\n",
      "Downloading video...\n",
      "Video downloaded to: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\\AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\n",
      "Trimming video...\n",
      "FFmpeg command: ffmpeg -i \"C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\\AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\" -ss 45 -t 22 -c copy \"C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\\trimmed_video.mp4\"\n",
      "Trimmed video saved to: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\\trimmed_video.mp4\n",
      "Temporary directory created: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\n",
      "Downloading video...\n",
      "Video downloaded to: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\\AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\n",
      "Trimming video...\n",
      "FFmpeg command: ffmpeg -i \"C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\\AMD at Computex 2024 AMD AI and High-Performance Computing with Dr Lisa Su.mp4\" -ss 45 -t 22 -c copy \"C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\\trimmed_video.mp4\"\n",
      "Trimmed video saved to: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\\trimmed_video.mp4\n",
      "Playing video...\n",
      "Cleaning up temporary directory: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp57kuf67g\n",
      "An error occurred: [WinError -2146959355] Server execution failed: 'C:\\\\Users\\\\kovtchar\\\\AppData\\\\Local\\\\Temp\\\\tmp57kuf67g\\\\trimmed_video.mp4'\n",
      "Playing video...\n",
      "Cleaning up temporary directory: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmpo_18g9j4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mplay_video_segment\u001b[1;34m(video_path, duration)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# For Windows\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError -2146959355] Server execution failed: 'C:\\\\Users\\\\kovtchar\\\\AppData\\\\Local\\\\Temp\\\\tmpo_18g9j4\\\\trimmed_video.mp4'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_dir \u001b[38;5;129;01mand\u001b[39;00m video_path:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[43mplay_video_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Clean up: remove the temporary directory and its contents\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaning up temporary directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mplay_video_segment\u001b[1;34m(video_path, duration)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlaying video...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# For Windows\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis script currently supports Windows only\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
    "youtube_url = 'https://www.youtube.com/watch?v=MCi8jgALPYA'\n",
    "\n",
    "start_time = 45  # Start time in seconds\n",
    "end_time = 67    # End time in seconds\n",
    "\n",
    "video_id = extract_video_id(youtube_url)\n",
    "\n",
    "if video_id:\n",
    "    print(f\"Extracted Video ID: {video_id}\")\n",
    "    transcript = fetch_transcript(video_id)\n",
    "\n",
    "    if transcript:\n",
    "        # Save the structured transcript (with timestamps)\n",
    "        save_transcript(transcript, 'transcript_structured.json')\n",
    "        save_formatted_transcript(transcript, 'transcript_formatted.txt')\n",
    "        print_transcript(transcript)\n",
    "\n",
    "        temp_dir, video_path = download_youtube_segment(video_id, start_time, end_time)\n",
    "        if temp_dir and video_path:\n",
    "            try:\n",
    "                play_video_segment(video_path, end_time - start_time)\n",
    "            finally:\n",
    "                # Clean up: remove the temporary directory and its contents\n",
    "                print(f\"Cleaning up temporary directory: {temp_dir}\")\n",
    "                for file in os.listdir(temp_dir):\n",
    "                    os.remove(os.path.join(temp_dir, file))\n",
    "                os.rmdir(temp_dir)\n",
    "        else:\n",
    "            print(\"Failed to download and trim the video segment.\")\n",
    "                play_youtube_segment(video_id, start_time, end_time)\n",
    "    else:\n",
    "        print(\"Could not extract a valid YouTube video ID from the provided URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory created: C:\\Users\\kovtchar\\AppData\\Local\\Temp\\tmp6n9ty6j7\n",
      "Downloading video...\n"
     ]
    }
   ],
   "source": [
    "play_youtube_segment(video_id, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websocket import create_connection\n",
    "from websocket._exceptions import WebSocketTimeoutException\n",
    "from aiohttp import web\n",
    "\n",
    "def prompt_llm_server(prompt):\n",
    "\n",
    "    # Create socket to talk to LLM server\n",
    "    uri = \"ws://localhost:8000/ws\"\n",
    "    llm_server_websocket = create_connection(uri)\n",
    "\n",
    "    # Send prompt to LLM server\n",
    "    # print(f\"Sending prompt to LLM server:\\n{prompt}\")\n",
    "    llm_server_websocket.send(prompt)\n",
    "\n",
    "    # Listen to LLM server until we receive </s> or no new\n",
    "    # tokens have been received in a while\n",
    "    while True:\n",
    "        try:\n",
    "            token = llm_server_websocket.recv()\n",
    "\n",
    "            # Set timeout after first token:\n",
    "            llm_server_websocket.sock.settimeout(5)\n",
    "\n",
    "            if token:\n",
    "                if \"</s>\" in token:\n",
    "                    token = token.replace(\"</s>\", \"\")\n",
    "                yield token\n",
    "        except WebSocketTimeoutException:\n",
    "            break\n",
    "\n",
    "    if llm_server_websocket.connected:\n",
    "        llm_server_websocket.close()\n",
    "\n",
    "def prompt_llm(query):\n",
    "    response = \"\"\n",
    "    new_card = True\n",
    "    prompt = f\"{llm_system_prompt}\\nUser: {query} [/INST]\\nAssistant: \"\n",
    "    # print(prompt)\n",
    "    for token in prompt_llm_server(prompt=prompt):\n",
    "\n",
    "        # Stream token to UI\n",
    "        # self.stream_to_ui(token, new_card=new_card)\n",
    "        new_card = False\n",
    "\n",
    "        response += token\n",
    "        print(token, end=\"\", flush=True)\n",
    "    return response\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_data(input_string):\n",
    "    # Find the JSON-formatted part of the string\n",
    "    json_match = re.search(r'\\{.*?\\}', input_string)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group()\n",
    "        try:\n",
    "            # Parse the JSON string\n",
    "            json_data = json.loads(json_str)\n",
    "            \n",
    "            # Extract the key and value\n",
    "            key, value = next(iter(json_data.items()))\n",
    "            \n",
    "            return key, value\n",
    "        except json.JSONDecodeError:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_states = [\n",
    "    (\"Index is currently not built and is empty.\\n\"\n",
    "    \"You do not have any access to the information from YouTube\\n\"\n",
    "    \"You need to perform youtube search using a tool.\"),\n",
    "    (\"Index is currently built and is not empty.\\n\"\n",
    "    \"You can now use the query engine to fetch information about the video\\n\")\n",
    "]\n",
    "llm_state = 0\n",
    "\n",
    "llm_system_prompt = (\n",
    "    \"[INST] <<SYS>>\\n\"\n",
    "    \"You are a YouTube-focused assistant called Clipy that helps user with YouTube by calling function tools.\\n\"\n",
    "    \"You are helpful by providing the necessary json-formatted queries in the form of {\\\"tool\\\" : \\\"query\\\"}:\\n\"\n",
    "    \"Do not include the results from the tools.\\n\"\n",
    "    \"In order to build the index, you have to first search YouTube.\\n\"\n",
    "    \"You only have ability to call the tools below, do not assume you have access to the output from the tools.\\n\"\n",
    "    \"1. youtube_search(query)\\n\"\n",
    "    \"2. build_vector_index(video_url)\\n\"\n",
    "    \"3. query_vector_index(query)\\n\"\n",
    "    \"\\n\"\n",
    "    \"Your tasks:\\n\"\n",
    "    \"2. Output a json that will be used in an external search tool for YouTube videos\\n\"\n",
    "    \"3. Call tool that can build an index from a video.\\n\"\n",
    "    \"1. Chat about YouTube content once index is built\\n\"\n",
    "    \"4. Answer questions from user using the index\\n\"\n",
    "    \"\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"- Answer a question given in a natural human-like manner.\\n\"\n",
    "    \"- Think step-by-step when answering questions.\\n\"\n",
    "    \"- When introducing yourself, keep it to just a single sentence, for example:\\n\"\n",
    "    \"\\\"Assistant: Hi, I can help you find information you're looking for on YouTube. Just ask me about any topic!\\\"\\n\"\n",
    "    \"- If no index exists, search YouTube and offer to build one\\n\"\n",
    "    \"- If an index does exist, use the query engine to answer questions.\\n\"\n",
    "    \"- If unsure, offer to search for more videos\\n\"\n",
    "    \"- Keep your answers short, concise and helpful\\n\"\n",
    "    \"- Search_query should be the subject of what the user is looking for, not a youtube link.\\n\"\n",
    "    \"- Do NOT provide search results, those are being provided by the external tools.\\n\"\n",
    "    \"- You can only provide the json formatted output to call the tools, you do not have access to the tools directly.\"\n",
    "    \"Current state of index:\\n\"\n",
    "    f\"{llm_states[llm_state]}\\n\"\n",
    "    \"\\n\"\n",
    "    \"When using a tool, end your response with only the tool function call. Do not answer search results.\"\n",
    "    \"Always use the most relevant tool for each task.\\n\"\n",
    "    \"When needing to use a tool, your response should be formatted, here is an example script:\\n\"\n",
    "    \"User: What kind of philantropy did Mr. Beast do?\"\n",
    "    \"Assistant: To answer your question, I first need to search YouTube for the answer. Calling the following tool: {\\\"youtube_search\\\" : \\\"Mr Beast philantropy\\\"} </s>\\n\"\n",
    "    \"<</SYS>>\\n\\n\"\n",
    ")\n",
    "    # \"{'build_vector_index' : video_url}\\n\"\n",
    "    # \"{'query_vector_index' : query}\\n\"\n",
    "\n",
    "# this system prompt has been verified to work with llama v2 7b 4bit on NPU.\n",
    "query_engine_system_prompt = (\n",
    "    \"[INST] <<SYS>>\\n\"\n",
    "    \"{context_str}\\n\\n\"\n",
    "    \"Think step-by-step to answer the query in a crisp, short and concise manner based on the information provided.\\n\"\n",
    "    \"If the answer does not exist in the given information, simply answer 'I don't know!'\\n\"\n",
    "    \"Do not mention or refer to the context or information provided in your response.\\n\"\n",
    "    \"Answer directly without any preamble or explanatory phrases about the source of your information.\\n\"\n",
    "    \"<</SYS>>\\n\\n\"\n",
    "    \"{query_str} [/INST]\\n\"\n",
    ")\n",
    "\n",
    "# prompt = \"What did Lisa Su talk about in the Computex Keynote in 2024?\"\n",
    "# prompt_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: youtube_search\n",
      "Value: Lisa Su Computex Keynote 2024\n",
      "Performing YouTube search with the following query: Lisa Su Computex Keynote 2024\n",
      "Found the following result:\n",
      "Title: AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su\n",
      "Description: The Future of High-Performance Computing in the AI Era Join us as Dr. Lisa Su delivers the Computex 2024 opening keynote and ...\n",
      "Published: 2024-06-03T03:12:08Z\n",
      "Fetching transcript from {'title': 'AMD at Computex 2024: AMD AI and High-Performance Computing with Dr. Lisa Su', 'description': 'The Future of High-Performance Computing in the AI Era Join us as Dr. Lisa Su delivers the Computex 2024 opening keynote and ...', 'video_id': 'MCi8jgALPYA', 'publish_time': '2024-06-03T03:12:08Z', 'channel_title': 'AMD'}.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_youtube_transcript_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m video_id \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m yt_links \u001b[38;5;241m=\u001b[39m [get_video_url(video_id)]\n\u001b[1;32m---> 19\u001b[0m yt_doc \u001b[38;5;241m=\u001b[39m \u001b[43mget_youtube_transcript_doc\u001b[49m(yt_links)\n\u001b[0;32m     20\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m yt_doc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdoc_id \u001b[38;5;241m=\u001b[39m doc_id\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_youtube_transcript_doc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"What did Lisa Su talk about in the Computex Keynote in 2024?\"\n",
    "# response = prompt_llm(prompt)\n",
    "\n",
    "key, value = extract_json_data(response)\n",
    "print(f\"Key: {key}\")\n",
    "print(f\"Value: {value}\")\n",
    "\n",
    "if key == \"youtube_search\":\n",
    "    print(f\"Performing YouTube search with the following query: {value}\")\n",
    "    result = youtube_search(value, max_results=1)\n",
    "    print(f\"Found the following result:\")\n",
    "    print(f\"Title: {result[0]['title']}\")\n",
    "    print(f\"Description: {result[0]['description']}\")\n",
    "    print(f\"Published: {result[0]['publish_time']}\")\n",
    "\n",
    "    print(f\"Fetching transcript from {result[0]}.\")\n",
    "    video_id = result[0]['video_id']\n",
    "    yt_links = [get_video_url(video_id)]\n",
    "    yt_doc = get_youtube_transcript_doc(yt_links)\n",
    "    doc_id = result[0]['title']\n",
    "    yt_doc[0].doc_id = doc_id\n",
    "\n",
    "    print(f\"Building index...\")\n",
    "    yt_index = build_vector_index(yt_doc)\n",
    "\n",
    "    print(f\"Done! Building query engine...\")\n",
    "    yt_engine = get_query_engine(yt_index)\n",
    "\n",
    "    print(\"All done!\")\n",
    "    print(\"Index and query engine is now ready to be used on your PC. Feel free to ask any questions about the video!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
